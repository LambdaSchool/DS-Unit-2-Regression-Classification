{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_214_assignment_ALEX_KAISER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lord-Kanzler/DS-Unit-2-Linear-Models/blob/master/module4-logistic-regression/LS_DS_214_assignment_ALEX_KAISER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIp5sf4THa9M",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- [x] Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- [x] Begin with baselines for classification.\n",
        "- [x] Use scikit-learn for logistic regression.\n",
        "- [x] Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- [x] Get your model's test accuracy. (One time, at the end.)\n",
        "- [x] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [x] Make exploratory visualizations.\n",
        "- [x] Do one-hot encoding.\n",
        "- [x] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [x] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLbzobdeHa9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TExnDn6iHa9T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhuSeiduHa9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR94UxrpHa9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUU7xpKbHa9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "df = df.drop(columns=['Rec', 'overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kuHmxNkHa9d",
        "colab_type": "code",
        "outputId": "b6578efa-ef64-4a35-a93d-80033a0f771b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(421, 59)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>California</td>\n",
              "      <td>1/18/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>California</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Asada</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>California</td>\n",
              "      <td>1/27/2016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>x</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Burrito       Date  Yelp  Google Chips  ...  Sushi  Avocado  Corn  Zucchini  Great\n",
              "0  California  1/18/2016   3.5     4.2   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "1  California  1/24/2016   3.5     3.3   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "2    Carnitas  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "3       Asada  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "4  California  1/27/2016   4.0     3.8     x  ...    NaN      NaN   NaN       NaN   True\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG9IKdqxP7uo",
        "colab_type": "code",
        "outputId": "e4735a3c-eeea-4026-881c-95ebbb5aaf43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Burrito            object\n",
              "Date               object\n",
              "Yelp              float64\n",
              "Google            float64\n",
              "Chips              object\n",
              "Cost              float64\n",
              "Hunger            float64\n",
              "Mass (g)          float64\n",
              "Density (g/mL)    float64\n",
              "Length            float64\n",
              "Circum            float64\n",
              "Volume            float64\n",
              "Tortilla          float64\n",
              "Temp              float64\n",
              "Meat              float64\n",
              "Fillings          float64\n",
              "Meat:filling      float64\n",
              "Uniformity        float64\n",
              "Salsa             float64\n",
              "Synergy           float64\n",
              "Wrap              float64\n",
              "Unreliable         object\n",
              "NonSD              object\n",
              "Beef               object\n",
              "Pico               object\n",
              "Guac               object\n",
              "Cheese             object\n",
              "Fries              object\n",
              "Sour cream         object\n",
              "Pork               object\n",
              "Chicken            object\n",
              "Shrimp             object\n",
              "Fish               object\n",
              "Rice               object\n",
              "Beans              object\n",
              "Lettuce            object\n",
              "Tomato             object\n",
              "Bell peper         object\n",
              "Carrots            object\n",
              "Cabbage            object\n",
              "Sauce              object\n",
              "Salsa.1            object\n",
              "Cilantro           object\n",
              "Onion              object\n",
              "Taquito            object\n",
              "Pineapple          object\n",
              "Ham                object\n",
              "Chile relleno      object\n",
              "Nopales            object\n",
              "Lobster            object\n",
              "Queso             float64\n",
              "Egg                object\n",
              "Mushroom           object\n",
              "Bacon              object\n",
              "Sushi              object\n",
              "Avocado            object\n",
              "Corn               object\n",
              "Zucchini           object\n",
              "Great                bool\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKRoJGkvT4cN",
        "colab_type": "code",
        "outputId": "03d451a0-70b2-4a26-9fdb-2121bcbc9de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Date to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "print(df.dtypes)\n",
        "print(df['Date'][0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Burrito                   object\n",
            "Date              datetime64[ns]\n",
            "Yelp                     float64\n",
            "Google                   float64\n",
            "Chips                     object\n",
            "Cost                     float64\n",
            "Hunger                   float64\n",
            "Mass (g)                 float64\n",
            "Density (g/mL)           float64\n",
            "Length                   float64\n",
            "Circum                   float64\n",
            "Volume                   float64\n",
            "Tortilla                 float64\n",
            "Temp                     float64\n",
            "Meat                     float64\n",
            "Fillings                 float64\n",
            "Meat:filling             float64\n",
            "Uniformity               float64\n",
            "Salsa                    float64\n",
            "Synergy                  float64\n",
            "Wrap                     float64\n",
            "Unreliable                object\n",
            "NonSD                     object\n",
            "Beef                      object\n",
            "Pico                      object\n",
            "Guac                      object\n",
            "Cheese                    object\n",
            "Fries                     object\n",
            "Sour cream                object\n",
            "Pork                      object\n",
            "Chicken                   object\n",
            "Shrimp                    object\n",
            "Fish                      object\n",
            "Rice                      object\n",
            "Beans                     object\n",
            "Lettuce                   object\n",
            "Tomato                    object\n",
            "Bell peper                object\n",
            "Carrots                   object\n",
            "Cabbage                   object\n",
            "Sauce                     object\n",
            "Salsa.1                   object\n",
            "Cilantro                  object\n",
            "Onion                     object\n",
            "Taquito                   object\n",
            "Pineapple                 object\n",
            "Ham                       object\n",
            "Chile relleno             object\n",
            "Nopales                   object\n",
            "Lobster                   object\n",
            "Queso                    float64\n",
            "Egg                       object\n",
            "Mushroom                  object\n",
            "Bacon                     object\n",
            "Sushi                     object\n",
            "Avocado                   object\n",
            "Corn                      object\n",
            "Zucchini                  object\n",
            "Great                       bool\n",
            "dtype: object\n",
            "2016-01-18 00:00:00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmHWYyVAkcxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 'Great' True/False to 1/0\n",
        "df['Great'] = df['Great']*1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2M7b2MGUyVS",
        "colab_type": "code",
        "outputId": "ab11c537-b1ef-4559-af3f-045a7d6eec33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Splits\n",
        "# train/test split\n",
        "import datetime as dt\n",
        "train = df[(df['Date'] <= dt.datetime(2016,12,31))]\n",
        "val = df[(df['Date'] >= dt.datetime(2017,1,1)) & (df['Date'] >= dt.datetime(2017,12,31))]\n",
        "test = df[(df['Date'] >= dt.datetime(2018,1,1))]\n",
        "train['Date']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     2016-01-18\n",
              "1     2016-01-24\n",
              "2     2016-01-24\n",
              "3     2016-01-24\n",
              "4     2016-01-27\n",
              "         ...    \n",
              "296   2016-12-02\n",
              "297   2016-12-02\n",
              "298   2016-12-10\n",
              "299   2016-12-10\n",
              "300   2016-12-15\n",
              "Name: Date, Length: 298, dtype: datetime64[ns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPFlKAcigMVC",
        "colab_type": "code",
        "outputId": "6f91677f-3623-4b0e-a172-467d98f4a2c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((298, 59), (38, 59), (38, 59))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo9RFsKbgd8U",
        "colab_type": "code",
        "outputId": "fd267d45-51d8-4438-912d-79e20c6787bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# baseline for classification\n",
        "target = 'Great'\n",
        "y_train = train[target]\n",
        "y_train.value_counts(normalize=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.590604\n",
              "1    0.409396\n",
              "Name: Great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFtKuPQckFMD",
        "colab_type": "code",
        "outputId": "1833681e-3d6b-43d9-fe5e-20e724ecffa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "majority_class = y_train.mode()[0]\n",
        "y_pred = [majority_class] * len(y_train)\n",
        "y_pred"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7CvEofWlr2q",
        "colab_type": "code",
        "outputId": "5eb430f6-cfe2-4681-9e15-36840894131f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_train, y_pred)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5906040268456376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM8Ojtp0mBiH",
        "colab_type": "code",
        "outputId": "7d6c808f-4dde-41ab-bff6-a252c0cad7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "# logistic regression\n",
        "train.describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>71.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>298.000000</td>\n",
              "      <td>283.000000</td>\n",
              "      <td>288.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>278.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>298.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.897183</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>6.896781</td>\n",
              "      <td>3.445286</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.770920</td>\n",
              "      <td>3.472315</td>\n",
              "      <td>3.706360</td>\n",
              "      <td>3.551215</td>\n",
              "      <td>3.519024</td>\n",
              "      <td>3.528870</td>\n",
              "      <td>3.395946</td>\n",
              "      <td>3.324640</td>\n",
              "      <td>3.540203</td>\n",
              "      <td>3.955068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.409396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.478680</td>\n",
              "      <td>0.371738</td>\n",
              "      <td>1.211412</td>\n",
              "      <td>0.852150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.081275</td>\n",
              "      <td>1.685043</td>\n",
              "      <td>0.137833</td>\n",
              "      <td>0.797606</td>\n",
              "      <td>0.991897</td>\n",
              "      <td>0.869483</td>\n",
              "      <td>0.850348</td>\n",
              "      <td>1.040457</td>\n",
              "      <td>1.089044</td>\n",
              "      <td>0.971226</td>\n",
              "      <td>0.922426</td>\n",
              "      <td>1.167341</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.492550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>2.990000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>6.850000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>11.950000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Yelp     Google        Cost  ...        Wrap  Queso       Great\n",
              "count  71.000000  71.000000  292.000000  ...  296.000000    0.0  298.000000\n",
              "mean    3.897183   4.142254    6.896781  ...    3.955068    NaN    0.409396\n",
              "std     0.478680   0.371738    1.211412  ...    1.167341    NaN    0.492550\n",
              "min     2.500000   2.900000    2.990000  ...    0.000000    NaN    0.000000\n",
              "25%     3.500000   4.000000    6.250000  ...    3.500000    NaN    0.000000\n",
              "50%     4.000000   4.200000    6.850000  ...    4.000000    NaN    0.000000\n",
              "75%     4.000000   4.400000    7.500000  ...    5.000000    NaN    1.000000\n",
              "max     4.500000   4.900000   11.950000  ...    5.000000    NaN    1.000000\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAN2uY3-tEjA",
        "colab_type": "code",
        "outputId": "f8b75755-a560-4796-d3af-452ca1f85e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# linear regression, to compare with logistic regression\n",
        "# 1. Import estimator class\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 2. Instantiate this class\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# 3. Arrange X feature matrices (already did y target vectors)\n",
        "features = ['Length', 'Circum', 'Volume' , 'Uniformity', 'Tortilla', 'Temp', 'Meat', 'Fillings', 'Synergy', 'Wrap']\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "X_test = test[features]\n",
        "\n",
        "# Impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_val_imputed = imputer.transform(X_val)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "y_val = val[target]\n",
        "y_test = test[target]\n",
        "\n",
        "# 4. Fit the model\n",
        "linear_reg.fit(X_train_imputed, y_train)\n",
        "print('Validation Accuracy', linear_reg.score(X_val_imputed, y_val))\n",
        "print('Test Accuracy', linear_reg.score(X_val_imputed, y_test))\n",
        "\n",
        "# 5. Apply the model to new data.\n",
        "# The predictions look like this ...\n",
        "print(\"Validation Prediction:\\n\", linear_reg.predict(X_val_imputed))\n",
        "print(\"Test Prediction:\\n\",linear_reg.predict(X_test_imputed))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.3734439995837274\n",
            "Test Accuracy 0.3734439995837274\n",
            "Validation Prediction:\n",
            " [ 1.34452534  0.79102744 -0.07415844  1.19813852  0.21218112  0.39858603\n",
            "  0.61488414  0.98267267  0.48605054  0.6693908   0.42913738  0.19969979\n",
            "  0.65232602  0.498595    0.62126873  0.65496836  0.60252529  0.08891124\n",
            "  0.08921106  0.18184962  0.26332017  0.77072401  0.26832362  0.53363902\n",
            "  0.7007757   0.40727963  0.35366783  1.10394629  0.66931659  0.98307113\n",
            "  0.36409297  0.69076809  0.86297192  0.24830859  0.58266623  0.56907547\n",
            "  0.84816752  0.75259579]\n",
            "Test Prediction:\n",
            " [ 1.34452534  0.79102744 -0.07415844  1.19813852  0.21218112  0.39858603\n",
            "  0.61488414  0.98267267  0.48605054  0.6693908   0.42913738  0.19969979\n",
            "  0.65232602  0.498595    0.62126873  0.65496836  0.60252529  0.08891124\n",
            "  0.08921106  0.18184962  0.26332017  0.77072401  0.26832362  0.53363902\n",
            "  0.7007757   0.40727963  0.35366783  1.10394629  0.66931659  0.98307113\n",
            "  0.36409297  0.69076809  0.86297192  0.24830859  0.58266623  0.56907547\n",
            "  0.84816752  0.75259579]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKizLU5atUwU",
        "colab_type": "code",
        "outputId": "01ffaf28-156a-4f5a-a0e4-ee51dd471dcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Get coefficients\n",
        "pd.Series(linear_reg.coef_, features)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Length        0.099400\n",
              "Circum        0.181422\n",
              "Volume       -2.560696\n",
              "Uniformity    0.035817\n",
              "Tortilla      0.057138\n",
              "Temp          0.050019\n",
              "Meat          0.119134\n",
              "Fillings      0.108768\n",
              "Synergy       0.159206\n",
              "Wrap          0.012637\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14IU0xL7tYQi",
        "colab_type": "code",
        "outputId": "a3709b7c-f7e2-4030-885a-42bca38ca1c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>71.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>175.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>298.000000</td>\n",
              "      <td>283.000000</td>\n",
              "      <td>288.000000</td>\n",
              "      <td>297.000000</td>\n",
              "      <td>292.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>278.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>298.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.897183</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>6.896781</td>\n",
              "      <td>3.445286</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.770920</td>\n",
              "      <td>3.472315</td>\n",
              "      <td>3.706360</td>\n",
              "      <td>3.551215</td>\n",
              "      <td>3.519024</td>\n",
              "      <td>3.528870</td>\n",
              "      <td>3.395946</td>\n",
              "      <td>3.324640</td>\n",
              "      <td>3.540203</td>\n",
              "      <td>3.955068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.409396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.478680</td>\n",
              "      <td>0.371738</td>\n",
              "      <td>1.211412</td>\n",
              "      <td>0.852150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.081275</td>\n",
              "      <td>1.685043</td>\n",
              "      <td>0.137833</td>\n",
              "      <td>0.797606</td>\n",
              "      <td>0.991897</td>\n",
              "      <td>0.869483</td>\n",
              "      <td>0.850348</td>\n",
              "      <td>1.040457</td>\n",
              "      <td>1.089044</td>\n",
              "      <td>0.971226</td>\n",
              "      <td>0.922426</td>\n",
              "      <td>1.167341</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.492550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>2.990000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>6.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.662500</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>6.850000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.750000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.870000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>11.950000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1.240000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Yelp     Google        Cost  ...        Wrap  Queso       Great\n",
              "count  71.000000  71.000000  292.000000  ...  296.000000    0.0  298.000000\n",
              "mean    3.897183   4.142254    6.896781  ...    3.955068    NaN    0.409396\n",
              "std     0.478680   0.371738    1.211412  ...    1.167341    NaN    0.492550\n",
              "min     2.500000   2.900000    2.990000  ...    0.000000    NaN    0.000000\n",
              "25%     3.500000   4.000000    6.250000  ...    3.500000    NaN    0.000000\n",
              "50%     4.000000   4.200000    6.850000  ...    4.000000    NaN    0.000000\n",
              "75%     4.000000   4.400000    7.500000  ...    5.000000    NaN    1.000000\n",
              "max     4.500000   4.900000   11.950000  ...    5.000000    NaN    1.000000\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24g5qNFDmSiO",
        "colab_type": "code",
        "outputId": "81c96baf-19e9-4fdc-eb77-b33ba679aa58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# investigate correlations in its dimensions - Validation\n",
        "# Import estimator class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate this class\n",
        "log_reg = LogisticRegression(solver='lbfgs', max_iter=200)\n",
        "\n",
        "# Arrange X feature matrices (already did y target vectors)\n",
        "features = ['Length', 'Circum', 'Volume' , 'Uniformity', 'Tortilla', 'Temp', 'Meat', 'Fillings', 'Synergy', 'Wrap']\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "# Impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_val_imputed = imputer.transform(X_val)\n",
        "\n",
        "# 4. Fit the model\n",
        "log_reg.fit(X_train_imputed, y_train)\n",
        "print('Validation Accuracy', log_reg.score(X_val_imputed, y_val))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7631578947368421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjUokWv4w5hA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2abc9ece-46c4-4589-af8c-92c6a3ccec48"
      },
      "source": [
        "# The predictions look like this\n",
        "log_reg.predict(X_val_imputed)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiPiSstU51kv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0e141d0-8759-47a2-bf41-8b97157942a1"
      },
      "source": [
        "# investigate correlations in its dimensions - Test\n",
        "# Import estimator class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Instantiate this class\n",
        "log_reg = LogisticRegression(solver='lbfgs', max_iter=200)\n",
        "\n",
        "# Arrange X feature matrices (already did y target vectors)\n",
        "features = ['Length', 'Circum', 'Volume' , 'Uniformity', 'Tortilla', 'Temp', 'Meat', 'Fillings', 'Synergy', 'Wrap']\n",
        "X_train = train[features]\n",
        "X_test = test[features]\n",
        "y_test = test[target]\n",
        "\n",
        "# Impute missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# 4. Fit the model\n",
        "log_reg.fit(X_train_imputed, y_train)\n",
        "print('Test Accuracy', log_reg.score(X_test_imputed, y_test))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy 0.7631578947368421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M-ylKsj6OrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a5ee3bab-2c03-4ab8-c7d7-7b41d6eb69e6"
      },
      "source": [
        "# The predictions look like this\n",
        "log_reg.predict(X_test_imputed)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nohW0oN_6tn6",
        "colab_type": "text"
      },
      "source": [
        "**Stretch Goal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmQwgRN0ykQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assigning variables\n",
        "features = ['Length', 'Circum', 'Volume' , 'Uniformity', 'Tortilla', 'Temp', 'Meat', 'Fillings', 'Synergy', 'Wrap']\n",
        "target = 'Great'\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "X_test = test[features]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6QbwX_Ty0hP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# inports\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lql5A7oy6iQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encoding\n",
        "encoder = ce.OneHotEncoder(use_cat_names=True)\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "X_test_encoded = encoder.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsm6lg6vy9R0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using imputer to replace NaN with mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train_encoded)\n",
        "X_val_imputed = imputer.transform(X_val_encoded)\n",
        "X_test_imputed = imputer.transform(X_test_encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZVndSZTzBUG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_val_scaled = scaler.fit_transform(X_val_imputed)\n",
        "X_test_scaled = scaler.fit_transform(X_test_imputed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P2ouGchzG0b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a5b33055-eb39-4dba-87da-cb295604b03b"
      },
      "source": [
        "# fit model\n",
        "model = LogisticRegressionCV()\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
              "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
              "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
              "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
              "                     solver='lbfgs', tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjLhd1BkzLKn",
        "colab_type": "code",
        "outputId": "dcc416a6-d929-4176-e78c-d8e153a7ccc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Validation Accuracy\n",
        "y_pred = model.predict(X_val_scaled)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7105263157894737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4gR3OMc8bHx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "75214ab0-998a-419b-e12c-04b5aa526cc9"
      },
      "source": [
        "# Test Accuracy\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7105263157894737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM7oxL3wzWEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "e937a40b-5117-460d-8766-8b8b90c4a714"
      },
      "source": [
        "# plot coefficients\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "coefficients = pd.Series(model.coef_[0], X_train_encoded.columns)\n",
        "coefficients.sort_values().plot.barh();"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAD4CAYAAADRuPC7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZpaFE4yZmWXx/wFv4WPShaDgfAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myhkHHDk9ErJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "43bb1ebb-14a0-4bf6-a776-fdf0e4b12c9d"
      },
      "source": [
        "# coefficient values\n",
        "coefficients"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Length        0.809631\n",
              "Circum        1.081519\n",
              "Volume       -1.253197\n",
              "Uniformity    0.391370\n",
              "Tortilla      0.599354\n",
              "Temp          0.527448\n",
              "Meat          1.389297\n",
              "Fillings      1.023402\n",
              "Synergy       2.024988\n",
              "Wrap          0.354320\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}