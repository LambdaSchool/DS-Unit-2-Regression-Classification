{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_212_solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOuAFD-KaHUB"
      },
      "source": [
        "BloomTech Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPhGM8L2aHUF"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cypYn9HaaHUG"
      },
      "source": [
        "# Module Project: Regression II\n",
        "\n",
        "In this project, you'll continue working with the New York City rent dataset you used in the last module project.\n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are as follows:\n",
        "\n",
        "- **Task 1:** Import `csv` file using `wrangle` function.\n",
        "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function to engineer two new features.\n",
        "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline mean absolute error for your dataset.\n",
        "- **Task 6:** Build and train a `Linearregression` model.\n",
        "- **Task 7:** Calculate the training and test mean absolute error for your model.\n",
        "- **Task 8:** Calculate the training and test $R^2$ score for your model.\n",
        "- **Stretch Goal:** Determine the three most important features for your linear regression model.\n",
        "\n",
        "**Note**\n",
        "\n",
        "You should limit yourself to the following libraries for this project:\n",
        "\n",
        "- `matplotlib`\n",
        "- `numpy`\n",
        "- `pandas`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74ZoHwXRbBdc"
      },
      "source": [
        "#Every Library Used In Notebook\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import r2_score as r2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5CzgMQQaHUH"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMy8YAn1aHUH"
      },
      "source": [
        "def wrangle(filepath):\n",
        "\n",
        "    #Reading in the Raw Data\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    #Formatting Column Names\n",
        "    df.columns = df.columns.str.upper().str.replace(' ','_')\n",
        "\n",
        "    #Declaring Subjective Wrangling Constants\n",
        "    high_cardinality_percentage_threshold = 0.1\n",
        "    max_cat = 5 #Max Unique Count to be Autoclassified as Categorical\n",
        "\n",
        "    #Column Classification Lists\n",
        "    date_cols = ['CREATED']\n",
        "    categorical_cols = []\n",
        "    numerical_cols = [] \n",
        "\n",
        "    for col in df:\n",
        "\n",
        "      #print(col, df[col].dtype, df[col].nunique())\n",
        "\n",
        "      #Find Categorical/Numerical Variables\n",
        "      if (df[col].dtype == 'object' or (df[col].nunique() in range(2,max_cat+1) )):\n",
        "        #print(\"Column: \",col)\n",
        "        if ~(col in categorical_cols):\n",
        "          categorical_cols.append(col)\n",
        "      else:\n",
        "        if ~(col in numerical_cols+categorical_cols):\n",
        "          numerical_cols.append(col)\n",
        "\n",
        "      #Format Dates\n",
        "      if( (col in categorical_cols) and (col in date_cols)):\n",
        "        df[col] = pd.to_datetime(df[col])\n",
        "\n",
        "      #Find Columns With Only One Value\n",
        "      if df[col].nunique() == 1:\n",
        "        if ~(col in single_value_cols):\n",
        "          single_value_cols.append(col)\n",
        "   \n",
        "    #Drop All Rows With Null Values\n",
        "    df = df.dropna(axis=0)\n",
        "\n",
        "    # Remove the most extreme 1% prices,\n",
        "    # the most extreme 1% latitudes, &\n",
        "    # the most extreme 1% longitudes\n",
        "    df = df[(df['PRICE'] >= np.percentile(df['PRICE'], 0.5)) & \n",
        "            (df['PRICE'] <= np.percentile(df['PRICE'], 99.5)) & \n",
        "            (df['LATITUDE'] >= np.percentile(df['LATITUDE'], 0.05)) & \n",
        "            (df['LATITUDE'] < np.percentile(df['LATITUDE'], 99.95)) &\n",
        "            (df['LONGITUDE'] >= np.percentile(df['LONGITUDE'], 0.05)) & \n",
        "            (df['LONGITUDE'] <= np.percentile(df['LONGITUDE'], 99.95))]\n",
        "\n",
        "    return df\n",
        "\n",
        "filepath = DATA_PATH + 'apartments/renthop-nyc.csv'\n",
        "\n",
        "df = df = wrangle(filepath)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e999biKpTxx_",
        "outputId": "ed2427d5-183f-4bb6-a95c-629cfb2d7a70"
      },
      "source": [
        "df['DISPLAY_ADDRESS'].nunique()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8552"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcFEzWNLUXr7",
        "outputId": "153369d8-3d5f-4baa-db1e-15acc880289e"
      },
      "source": [
        "df['STREET_ADDRESS'].nunique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14635"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HcB0uM7bffe"
      },
      "source": [
        "#THERE ARE REPEAT DATES\n",
        "#df[ df['CREATED'].duplicated() ]\n",
        "\n",
        "cols_to_drop = ['CREATED', 'DESCRIPTION', 'DISPLAY_ADDRESS', 'STREET_ADDRESS']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IShi9_zwaHUI"
      },
      "source": [
        "**Task 1:** Add the following functionality to the above `wrangle` function.\n",
        "\n",
        "- The `'created'` column will parsed as a `DateTime` object and set as the `index` of the DataFrame. \n",
        "- Rows with `NaN` values will be dropped.\n",
        "\n",
        "Then use your modified function to import the `renthop-nyc.csv` file into a DataFrame named `df`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_pWv58eaHUJ"
      },
      "source": [
        "**Task 2:** Using your `pandas` and dataviz skills decide on two features that you want to engineer for your dataset. Next, modify your `wrangle` function to add those features. \n",
        "\n",
        "**Note:** You can learn more about feature engineering [here](https://en.wikipedia.org/wiki/Feature_engineering). Here are some ideas for new features:\n",
        "\n",
        "- Does the apartment have a description?\n",
        "- Length of description.\n",
        "- Total number of perks that apartment has.\n",
        "- Are cats _or_ dogs allowed?\n",
        "- Are cats _and_ dogs allowed?\n",
        "- Total number of rooms (beds + baths)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke5jcBv-9m4o",
        "outputId": "7898a256-6cb3-4467-db6a-1d15fc4b279f"
      },
      "source": [
        "print(list(df.columns))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BATHROOMS', 'BEDROOMS', 'CREATED', 'DESCRIPTION', 'DISPLAY_ADDRESS', 'LATITUDE', 'LONGITUDE', 'PRICE', 'STREET_ADDRESS', 'INTEREST_LEVEL', 'ELEVATOR', 'CATS_ALLOWED', 'HARDWOOD_FLOORS', 'DOGS_ALLOWED', 'DOORMAN', 'DISHWASHER', 'NO_FEE', 'LAUNDRY_IN_BUILDING', 'FITNESS_CENTER', 'PRE-WAR', 'LAUNDRY_IN_UNIT', 'ROOF_DECK', 'OUTDOOR_SPACE', 'DINING_ROOM', 'HIGH_SPEED_INTERNET', 'BALCONY', 'SWIMMING_POOL', 'NEW_CONSTRUCTION', 'TERRACE', 'EXCLUSIVE', 'LOFT', 'GARDEN_PATIO', 'WHEELCHAIR_ACCESS', 'COMMON_OUTDOOR_SPACE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fVQAhbyaHUK",
        "outputId": "4563ff00-b454-495d-c42c-d7bbdd9126c0"
      },
      "source": [
        "# Conduct your exploratory data analysis here, \n",
        "# and then modify the function above.\n",
        "\n",
        "# Feature Formatting\n",
        "df.loc[df['INTEREST_LEVEL'] == 'low', \"INTEREST_LEVEL\"] = 0\n",
        "df.loc[df['INTEREST_LEVEL'] == 'medium', \"INTEREST_LEVEL\"] = 1\n",
        "df.loc[df['INTEREST_LEVEL'] == 'high', \"INTEREST_LEVEL\"] = 2\n",
        "\n",
        "# Additional Feature #1\n",
        "feature1 = 'TOTAL_PERKS'\n",
        "df[feature1] = np.repeat(0,df.shape[0])\n",
        "perks = list(df.nunique()[ df.nunique() == 2].index)\n",
        "perks.remove('NEW_CONSTRUCTION')\n",
        "perks.remove('EXCLUSIVE')\n",
        "for col in perks:\n",
        "  df[feature1] += df[col]\n",
        "print(df.groupby(by=feature1)['PRICE'].mean()); print()\n",
        "\n",
        "# Additional Feature #2\n",
        "feature2 = 'ANYTHING_OUTDOORS'\n",
        "df[feature2] = 1 - (1-df['BALCONY'])*(1-df['SWIMMING_POOL'])*(1-df['GARDEN_PATIO'])*(1-df['COMMON_OUTDOOR_SPACE'])*(1-df['TERRACE'])*(1-df['OUTDOOR_SPACE'])*(1-df['ROOF_DECK'])\n",
        "print(df.groupby(by=feature2)['PRICE'].mean()); print()\n",
        "#plt.title(feature2+' vs PRICE')\n",
        "#plt.scatter(y=df['PRICE'], x=df[feature2]);\n",
        "\n",
        "# plt.scatter(y=df['PRICE'], x=df['DOGS_ALLOWED']);\n",
        "# print(df.groupby(by='DOGS_ALLOWED')['PRICE'].mean()); print()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOTAL_PERKS\n",
            "0     2804.442364\n",
            "1     2845.290182\n",
            "2     3066.058111\n",
            "3     3212.627418\n",
            "4     3659.147171\n",
            "5     3777.141882\n",
            "6     3985.879926\n",
            "7     4088.913563\n",
            "8     4129.486201\n",
            "9     4266.277477\n",
            "10    4370.703658\n",
            "11    4505.367786\n",
            "12    4530.938947\n",
            "13    4872.078324\n",
            "14    4711.526132\n",
            "15    4870.595890\n",
            "16    4899.337079\n",
            "17    4813.633333\n",
            "18    4277.000000\n",
            "Name: PRICE, dtype: float64\n",
            "\n",
            "ANYTHING_OUTDOORS\n",
            "0    3349.794731\n",
            "1    4173.225573\n",
            "Name: PRICE, dtype: float64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ld934WzaHUK"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your DataFrame `df` into a feature matrix `X` and the target vector `y`. You want to predict `'price'`.\n",
        "\n",
        "**Note:** In contrast to the last module project, this time you should include _all_ the numerical features in your dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOGf78jMaHUL"
      },
      "source": [
        "target = 'PRICE'\n",
        "features = list(df.columns)\n",
        "for col in cols_to_drop:\n",
        "  features.remove(col)\n",
        "features.remove(target)\n",
        "\n",
        "X = df[ features ]\n",
        "y = df[target]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcxikicMaHUL"
      },
      "source": [
        "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
        "\n",
        "- Your training set should include data from April and May 2016. \n",
        "- Your test set should include data from June 2016."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBUOAPjZaHUL"
      },
      "source": [
        "mask = ( (df['CREATED'].dt.month == 4) | (df['CREATED'].dt.month == 5) )\n",
        "\n",
        "X_train, y_train = X.loc[mask], y.loc[mask]\n",
        "X_test, y_test = X.loc[~mask], y.loc[~mask]\n",
        "\n",
        "#print(df[~mask]['CREATED'].dt.month.value_counts()) #To Check That The Split Worked"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nVewDmqaHUM"
      },
      "source": [
        "# III. Establish Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYZk5iagaHUM"
      },
      "source": [
        "**Task 5:** Since this is a **regression** problem, you need to calculate the baseline mean absolute error for your model. First, calculate the mean of `y_train`. Next, create a list `y_pred` that has the same length as `y_train` and where every item in the list is the mean. Finally, use `mean_absolute_error` to calculate your baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkxGqp6qaHUM",
        "outputId": "68e9a4fb-8cea-46bf-e2c7-b82a37959896"
      },
      "source": [
        "y_pred_baseline = [ y_train.mean() ] * len(y_train)\n",
        "baseline_mae = mae(y_train, y_pred_baseline)\n",
        "print('Baseline MAE:', baseline_mae)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline MAE: 1202.398300781848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpgQXae5aHUN"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build and train a `LinearRegression` model named `model` using your feature matrix `X_train` and your target vector `y_train`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rae9OxSZaHUN",
        "outputId": "480015a3-dc85-4359-980f-d2f5ce0533df"
      },
      "source": [
        "model = LinearRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DP66cMuSaHUN"
      },
      "source": [
        "# V. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and test mean absolute error for your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-8eHIbzaHUO",
        "outputId": "ee805bd2-b97a-4c52-9fdd-38d4253275e8"
      },
      "source": [
        "training_mae = mae(y_train, model.predict(X_train))\n",
        "test_mae = mae(y_test, model.predict(X_test))\n",
        "\n",
        "print('Training MAE:', training_mae)\n",
        "print('Test MAE:', test_mae)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MAE: 672.531584013441\n",
            "Test MAE: 675.8599022993726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG0Ds2TDaHUO"
      },
      "source": [
        "**Task 8:** Calculate the training and test $R^2$ score for your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqK1dTvzaHUO",
        "outputId": "2b4b3068-e473-4a1e-c259-3051057ff7a5"
      },
      "source": [
        "training_r2 = r2(y_train, model.predict(X_train))\n",
        "test_r2 = r2(y_train, model.predict(X_train))\n",
        "\n",
        "print('Training R2:', training_r2)\n",
        "print('Test R2:', test_r2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training R2: 0.6362112842090302\n",
            "Test R2: 0.6362112842090302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K2ik0QvaHUP"
      },
      "source": [
        "# VI. Communicate Results\n",
        "\n",
        "**Stretch Goal:** What are the three most influential coefficients in your linear model? You should consider the _absolute value_ of each coefficient, so that it doesn't matter if it's positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYLw7elqaHUP",
        "outputId": "c2e3606a-5793-496c-e82c-7a9a5bd2c52e"
      },
      "source": [
        "var = 'ABS COEF'\n",
        "coef_df = pd.DataFrame(model.coef_, index=features, columns=[var])\n",
        "print(coef_df.abs().sort_values(by=var, ascending=False))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          ABS COEF\n",
            "LONGITUDE             13067.936829\n",
            "BATHROOMS              1703.109841\n",
            "LATITUDE               1246.013084\n",
            "BEDROOMS                486.029874\n",
            "LAUNDRY_IN_UNIT         454.473246\n",
            "INTEREST_LEVEL          412.073801\n",
            "DOORMAN                 392.246581\n",
            "HIGH_SPEED_INTERNET     307.361491\n",
            "ROOF_DECK               255.603326\n",
            "DINING_ROOM             244.134217\n",
            "EXCLUSIVE               211.519199\n",
            "COMMON_OUTDOOR_SPACE    196.048460\n",
            "HARDWOOD_FLOORS         173.458382\n",
            "OUTDOOR_SPACE           167.972423\n",
            "WHEELCHAIR_ACCESS       151.102351\n",
            "TERRACE                 150.019561\n",
            "LAUNDRY_IN_BUILDING     135.234591\n",
            "NO_FEE                  130.037915\n",
            "NEW_CONSTRUCTION        126.646834\n",
            "PRE-WAR                 117.645647\n",
            "ANYTHING_OUTDOORS       115.988931\n",
            "LOFT                    107.141610\n",
            "ELEVATOR                105.206171\n",
            "BALCONY                  93.207392\n",
            "GARDEN_PATIO             85.592250\n",
            "FITNESS_CENTER           75.901349\n",
            "CATS_ALLOWED             59.947035\n",
            "DOGS_ALLOWED             44.542066\n",
            "DISHWASHER               27.993766\n",
            "TOTAL_PERKS              26.615942\n",
            "SWIMMING_POOL             4.036066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W2MYYxWXDDT"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}