{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "db_LS_DS_214_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daniel-Benson-Poe/DS-Unit-2-Linear-Models/blob/master/db_LS_DS_214_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2RDtL0PoGc9",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "\n",
        "## Assignment ðŸŒ¯\n",
        "\n",
        "You'll use a [**dataset of 400+ burrito reviews**](https://srcole.github.io/100burritos/). How accurately can you predict whether a burrito is rated 'Great'?\n",
        "\n",
        "> We have developed a 10-dimensional system for rating the burritos in San Diego. ... Generate models for what makes a burrito great and investigate correlations in its dimensions.\n",
        "\n",
        "- [ ] Do train/validate/test split. Train on reviews from 2016 & earlier. Validate on 2017. Test on 2018 & later.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Use scikit-learn for logistic regression.\n",
        "- [ ] Get your model's validation accuracy. (Multiple times if you try multiple iterations.)\n",
        "- [ ] Get your model's test accuracy. (One time, at the end.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Make exploratory visualizations.\n",
        "- [ ] Do one-hot encoding.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Get and plot your coefficients.\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvGF34znoGdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data downloaded from https://srcole.github.io/100burritos/\n",
        "import pandas as pd\n",
        "df = pd.read_csv(DATA_PATH+'burritos/burritos.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g70NJk3yoGdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Derive binary classification target:\n",
        "# We define a 'Great' burrito as having an\n",
        "# overall rating of 4 or higher, on a 5 point scale.\n",
        "# Drop unrated burritos.\n",
        "df = df.dropna(subset=['overall'])\n",
        "df['Great'] = df['overall'] >= 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fw9Anv8oGdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean/combine the Burrito categories\n",
        "df['Burrito'] = df['Burrito'].str.lower()\n",
        "\n",
        "california = df['Burrito'].str.contains('california')\n",
        "asada = df['Burrito'].str.contains('asada')\n",
        "surf = df['Burrito'].str.contains('surf')\n",
        "carnitas = df['Burrito'].str.contains('carnitas')\n",
        "\n",
        "df.loc[california, 'Burrito'] = 'California'\n",
        "df.loc[asada, 'Burrito'] = 'Asada'\n",
        "df.loc[surf, 'Burrito'] = 'Surf & Turf'\n",
        "df.loc[carnitas, 'Burrito'] = 'Carnitas'\n",
        "df.loc[~california & ~asada & ~surf & ~carnitas, 'Burrito'] = 'Other'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-US1LAu-oGda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some high cardinality categoricals\n",
        "df = df.drop(columns=['Notes', 'Location', 'Reviewer', 'Address', 'URL', 'Neighborhood'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpghTAwkoGdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drop some columns to prevent \"leakage\"\n",
        "df = df.drop(columns=['Rec', 'overall'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnx5tAJa4bpJ",
        "colab_type": "text"
      },
      "source": [
        "Train/Validate/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf4mi7yboGdn",
        "colab_type": "code",
        "outputId": "95a3cf58-8388-44c6-fd04-4232ab2fbab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "# Look at the first five rows of the dataframe\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Queso</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>California</td>\n",
              "      <td>1/18/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>California</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Asada</td>\n",
              "      <td>1/24/2016</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>California</td>\n",
              "      <td>1/27/2016</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>x</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Burrito       Date  Yelp  Google Chips  ...  Sushi  Avocado  Corn  Zucchini  Great\n",
              "0  California  1/18/2016   3.5     4.2   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "1  California  1/24/2016   3.5     3.3   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "2    Carnitas  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "3       Asada  1/24/2016   NaN     NaN   NaN  ...    NaN      NaN   NaN       NaN  False\n",
              "4  California  1/27/2016   4.0     3.8     x  ...    NaN      NaN   NaN       NaN   True\n",
              "\n",
              "[5 rows x 59 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smJJrD8q2MRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create train, validate, and test sets; train <= 2016; validate == 2017; test >= 2018\n",
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "# Create cut offs\n",
        "cut1 = pd.to_datetime('2017-01-01')\n",
        "cut2 = pd.to_datetime('2018-01-01')\n",
        "# Create train set\n",
        "train = df[df['Date'] < cut1]\n",
        "# Create validation set\n",
        "val = df[(df['Date'] > cut1) &\n",
        "         (df['Date'] < cut2)]\n",
        "# Create test set\n",
        "test = df[df['Date'] > cut2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R303rlRh4IED",
        "colab_type": "code",
        "outputId": "026583d7-a651-4fdc-8322-5be346513ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        }
      },
      "source": [
        "train, val"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(        Burrito       Date  Yelp  Google  ... Avocado  Corn  Zucchini  Great\n",
              " 0    California 2016-01-18   3.5     4.2  ...     NaN   NaN       NaN  False\n",
              " 1    California 2016-01-24   3.5     3.3  ...     NaN   NaN       NaN  False\n",
              " 2      Carnitas 2016-01-24   NaN     NaN  ...     NaN   NaN       NaN  False\n",
              " 3         Asada 2016-01-24   NaN     NaN  ...     NaN   NaN       NaN  False\n",
              " 4    California 2016-01-27   4.0     3.8  ...     NaN   NaN       NaN   True\n",
              " ..          ...        ...   ...     ...  ...     ...   ...       ...    ...\n",
              " 296  California 2016-12-02   4.0     4.3  ...     NaN   NaN       NaN  False\n",
              " 297       Other 2016-12-02   NaN     NaN  ...     NaN   NaN       NaN  False\n",
              " 298  California 2016-12-10   3.5     3.7  ...     NaN   NaN       NaN  False\n",
              " 299       Asada 2016-12-10   NaN     NaN  ...     NaN   NaN       NaN  False\n",
              " 300       Other 2016-12-15   4.5     4.6  ...     NaN   NaN       NaN  False\n",
              " \n",
              " [298 rows x 59 columns],\n",
              "         Burrito       Date  Yelp  Google  ... Avocado  Corn  Zucchini  Great\n",
              " 301  California 2017-01-04   NaN     NaN  ...     NaN   NaN       NaN  False\n",
              " 302       Other 2017-01-04   NaN     NaN  ...     NaN   NaN       NaN  False\n",
              " 303       Other 2017-01-07   NaN     NaN  ...     NaN   NaN       NaN  False\n",
              " 304       Other 2017-01-07   NaN     NaN  ...     NaN   NaN       NaN  False\n",
              " 305       Other 2017-01-10   NaN     NaN  ...     NaN   NaN       NaN  False\n",
              " ..          ...        ...   ...     ...  ...     ...   ...       ...    ...\n",
              " 381  California 2017-09-05   NaN     NaN  ...     NaN   NaN       NaN   True\n",
              " 382  California 2017-09-05   NaN     NaN  ...     NaN   NaN       NaN   True\n",
              " 383       Other 2017-12-16   4.0     4.5  ...     NaN   NaN       NaN  False\n",
              " 384  California 2017-12-29   NaN     NaN  ...     NaN   NaN       NaN   True\n",
              " 385  California 2017-12-29   NaN     NaN  ...     NaN   NaN       NaN   True\n",
              " \n",
              " [85 rows x 59 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRfkfX5T4VLB",
        "colab_type": "text"
      },
      "source": [
        "Begin with baseline for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5DBXMQ94KDI",
        "colab_type": "code",
        "outputId": "92d691da-f5ca-4ef5-b847-a9f3ebb6d48f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "target = 'Great' # Set target\n",
        "y_train = train[target] # Create y_train \n",
        "y_train.value_counts(normalize=True) # Check the value counts of y in percent format"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    0.590604\n",
              "True     0.409396\n",
              "Name: Great, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOypIgJ54xT2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "majority_class = y_train.mode()[0] # Find majority class\n",
        "y_pred_train = [majority_class]*len(y_train) # Make predicions based on majority class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-v2tDBhE49Yy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41757d39-b4e0-4b84-ad74-fde32d23c568"
      },
      "source": [
        "y_pred_train"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFxxi6O35DlT",
        "colab_type": "code",
        "outputId": "ce69a114-fe2e-47dd-de40-1e9b36e78f32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Find the baseline accuracy if guessing majority class for every prediction\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_train, y_pred_train)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5906040268456376"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uaIjI_zEht2",
        "colab_type": "code",
        "outputId": "561daf25-333c-4a92-b58e-7dfed88dcdf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_val = val[target]\n",
        "y_pred = [majority_class]*len(y_val)\n",
        "accuracy_score(y_val, y_pred)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5529411764705883"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vifwK6LLFNWB",
        "colab_type": "text"
      },
      "source": [
        "For fun, let's look at that from a linear regression view: just an attempt to really hammer in the intuition for logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb_FWILwEtyC",
        "colab_type": "code",
        "outputId": "39a4ca3a-a595-4c5b-efcc-8240d0691b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "train.describe(exclude='number')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Date</th>\n",
              "      <th>Chips</th>\n",
              "      <th>Unreliable</th>\n",
              "      <th>NonSD</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Chicken</th>\n",
              "      <th>Shrimp</th>\n",
              "      <th>Fish</th>\n",
              "      <th>Rice</th>\n",
              "      <th>Beans</th>\n",
              "      <th>Lettuce</th>\n",
              "      <th>Tomato</th>\n",
              "      <th>Bell peper</th>\n",
              "      <th>Carrots</th>\n",
              "      <th>Cabbage</th>\n",
              "      <th>Sauce</th>\n",
              "      <th>Salsa.1</th>\n",
              "      <th>Cilantro</th>\n",
              "      <th>Onion</th>\n",
              "      <th>Taquito</th>\n",
              "      <th>Pineapple</th>\n",
              "      <th>Ham</th>\n",
              "      <th>Chile relleno</th>\n",
              "      <th>Nopales</th>\n",
              "      <th>Lobster</th>\n",
              "      <th>Egg</th>\n",
              "      <th>Mushroom</th>\n",
              "      <th>Bacon</th>\n",
              "      <th>Sushi</th>\n",
              "      <th>Avocado</th>\n",
              "      <th>Corn</th>\n",
              "      <th>Zucchini</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>298</td>\n",
              "      <td>298</td>\n",
              "      <td>22</td>\n",
              "      <td>27</td>\n",
              "      <td>5</td>\n",
              "      <td>168</td>\n",
              "      <td>143</td>\n",
              "      <td>139</td>\n",
              "      <td>149</td>\n",
              "      <td>119</td>\n",
              "      <td>85</td>\n",
              "      <td>43</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>33</td>\n",
              "      <td>32</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>37</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>5</td>\n",
              "      <td>110</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>California</td>\n",
              "      <td>2016-08-30 00:00:00</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>x</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>118</td>\n",
              "      <td>29</td>\n",
              "      <td>19</td>\n",
              "      <td>27</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>115</td>\n",
              "      <td>101</td>\n",
              "      <td>121</td>\n",
              "      <td>97</td>\n",
              "      <td>63</td>\n",
              "      <td>29</td>\n",
              "      <td>19</td>\n",
              "      <td>17</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>33</td>\n",
              "      <td>5</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>first</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2011-05-16 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>last</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2016-12-15 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Burrito                 Date Chips  ... Corn Zucchini  Great\n",
              "count          298                  298    22  ...    2        1    298\n",
              "unique           5                  110     2  ...    2        1      2\n",
              "top     California  2016-08-30 00:00:00     x  ...    x        x  False\n",
              "freq           118                   29    19  ...    1        1    176\n",
              "first          NaN  2011-05-16 00:00:00   NaN  ...  NaN      NaN    NaN\n",
              "last           NaN  2016-12-15 00:00:00   NaN  ...  NaN      NaN    NaN\n",
              "\n",
              "[6 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGMPskKBGUCo",
        "colab_type": "code",
        "outputId": "9962e6a2-7645-4329-b636-dbdf959d347f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "val.describe()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Queso</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>84.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>83.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.846154</td>\n",
              "      <td>4.353846</td>\n",
              "      <td>7.582024</td>\n",
              "      <td>3.679518</td>\n",
              "      <td>546.181818</td>\n",
              "      <td>0.675277</td>\n",
              "      <td>20.594595</td>\n",
              "      <td>22.247297</td>\n",
              "      <td>0.819595</td>\n",
              "      <td>3.525294</td>\n",
              "      <td>3.876250</td>\n",
              "      <td>3.718675</td>\n",
              "      <td>3.528571</td>\n",
              "      <td>3.681928</td>\n",
              "      <td>3.488824</td>\n",
              "      <td>3.412651</td>\n",
              "      <td>3.674706</td>\n",
              "      <td>4.104706</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.473665</td>\n",
              "      <td>0.359665</td>\n",
              "      <td>2.222494</td>\n",
              "      <td>0.602992</td>\n",
              "      <td>144.445619</td>\n",
              "      <td>0.080468</td>\n",
              "      <td>1.920038</td>\n",
              "      <td>2.042240</td>\n",
              "      <td>0.182490</td>\n",
              "      <td>0.751333</td>\n",
              "      <td>0.908643</td>\n",
              "      <td>0.686841</td>\n",
              "      <td>0.634466</td>\n",
              "      <td>0.782140</td>\n",
              "      <td>0.956008</td>\n",
              "      <td>0.788014</td>\n",
              "      <td>0.785040</td>\n",
              "      <td>0.883298</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>4.750000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>350.000000</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>6.750000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>450.000000</td>\n",
              "      <td>0.619485</td>\n",
              "      <td>19.500000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>7.240000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>540.000000</td>\n",
              "      <td>0.658099</td>\n",
              "      <td>20.750000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.795000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>595.000000</td>\n",
              "      <td>0.721726</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.917500</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.100000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>925.000000</td>\n",
              "      <td>0.865672</td>\n",
              "      <td>24.500000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>1.540000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Yelp     Google       Cost  ...    Synergy       Wrap  Queso\n",
              "count  13.000000  13.000000  84.000000  ...  85.000000  85.000000    0.0\n",
              "mean    3.846154   4.353846   7.582024  ...   3.674706   4.104706    NaN\n",
              "std     0.473665   0.359665   2.222494  ...   0.785040   0.883298    NaN\n",
              "min     3.000000   3.800000   4.750000  ...   1.000000   1.500000    NaN\n",
              "25%     3.500000   4.100000   6.750000  ...   3.500000   3.500000    NaN\n",
              "50%     4.000000   4.400000   7.240000  ...   3.800000   4.000000    NaN\n",
              "75%     4.000000   4.500000   7.900000  ...   4.000000   5.000000    NaN\n",
              "max     4.500000   5.000000  25.000000  ...   5.000000   5.000000    NaN\n",
              "\n",
              "[8 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtUbl8amFacX",
        "colab_type": "code",
        "outputId": "ebc5f1db-764d-4e0d-a0bc-d0cbdf4004e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# 1. Import estimator class\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 2. Instantiate class\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# 3. Arrange X feature matrices (already did y target vectors)\n",
        "features = ['Yelp',\t'Google',\t'Cost',\t'Hunger',\t'Mass (g)',\t'Density (g/mL)',\n",
        "            'Length',\t'Circum',\t'Volume',\t'Tortilla',\t'Temp',\t'Meat',\t'Fillings',\n",
        "            'Meat:filling',\t'Uniformity',\t'Salsa',\t'Synergy',\t'Wrap',\t'Queso']\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "\n",
        "# Impute missing values\n",
        "from sklearn.impute import SimpleImputer # import imputer\n",
        "imputer = SimpleImputer() # instantiate imputer\n",
        "X_train_imputed = imputer.fit_transform(X_train) # fit_transform X_train\n",
        "X_val_imputed = imputer.transform(X_val) # transform X_val\n",
        "\n",
        "# 4. Fit the model\n",
        "linear_reg.fit(X_train_imputed, y_train) \n",
        "\n",
        "# 5. Apply model to new data\n",
        "linear_reg.predict(X_val_imputed)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.53160422,  0.49639941,  0.66055462,  0.59571679, -0.12212491,\n",
              "        0.13538657,  0.83359786,  0.49877043, -0.02481807,  0.77643143,\n",
              "        0.75694877, -0.05553553,  0.28293718,  0.31358049,  1.03604807,\n",
              "        0.41605914,  0.40906669,  0.64362603,  0.63899424,  1.11097651,\n",
              "        0.63493382,  0.47753632,  0.1188471 ,  0.54810157,  0.65757879,\n",
              "        0.68587925,  0.70437383,  0.42792166,  0.48334497,  0.68371865,\n",
              "        0.7611789 ,  0.47186949,  0.3721218 ,  0.39950396, -0.09902347,\n",
              "       -0.01878977,  0.42972242,  0.57873428,  0.40398879,  0.50102965,\n",
              "        0.41968988,  0.43513575,  0.47879177,  0.60973024,  0.61424744,\n",
              "        0.4568679 ,  0.16016893,  0.19973556,  0.66299179, -0.19781305,\n",
              "        0.22785082,  0.45941645,  0.84638977,  0.76738021,  0.43725022,\n",
              "        0.16614088,  0.2230091 ,  0.18621903,  0.38512429,  0.38367767,\n",
              "       -0.44962382,  0.33373709, -0.08414513,  0.47801874,  0.49522269,\n",
              "        0.84514189,  0.56011928,  0.98405841,  0.5797118 ,  0.40052876,\n",
              "        1.33900076,  0.83554627,  0.57774095,  0.74993308, -0.10734979,\n",
              "        0.42313629,  0.16433945,  0.71309325,  0.77031671,  0.87851511,\n",
              "        0.55946083,  0.66459965,  0.54392439,  0.63026513,  1.18985414])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YigIdemMHiLP",
        "colab_type": "code",
        "outputId": "146143ad-fcda-4eb5-feb6-9054948eb0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "features"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Yelp',\n",
              " 'Google',\n",
              " 'Cost',\n",
              " 'Hunger',\n",
              " 'Mass (g)',\n",
              " 'Density (g/mL)',\n",
              " 'Length',\n",
              " 'Circum',\n",
              " 'Volume',\n",
              " 'Tortilla',\n",
              " 'Temp',\n",
              " 'Meat',\n",
              " 'Fillings',\n",
              " 'Meat:filling',\n",
              " 'Uniformity',\n",
              " 'Salsa',\n",
              " 'Synergy',\n",
              " 'Wrap',\n",
              " 'Queso']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE5fS_MRIUNI",
        "colab_type": "code",
        "outputId": "2fae76f4-a66a-4fbc-8d2e-ea07fd991686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Get coefficients\n",
        "linear_reg.coef_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.11004571, -0.13194436,  0.03994151,  0.0102132 ,  0.10600872,\n",
              "        0.18149784, -2.6815502 ,  0.05838255,  0.05195749,  0.09834228,\n",
              "        0.09506547,  0.06605855,  0.01605043,  0.03328156,  0.13140973,\n",
              "        0.00596809])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhGlT_syv5BC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "cbc490d6-c752-4d10-c63d-1a442f561f81"
      },
      "source": [
        "X_train.sample(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Mass (g)</th>\n",
              "      <th>Density (g/mL)</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Queso</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>4.99</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.66</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.60</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.49</td>\n",
              "      <td>4.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.7</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.25</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.49</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16.5</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.82</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>4.5</td>\n",
              "      <td>4.1</td>\n",
              "      <td>6.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.87</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>4.5</td>\n",
              "      <td>4.7</td>\n",
              "      <td>7.99</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>6.60</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Yelp  Google  Cost  Hunger  ...  Salsa  Synergy  Wrap  Queso\n",
              "183   4.0     3.9  4.99     3.5  ...    2.5      3.0   4.0    NaN\n",
              "63    NaN     NaN  6.60     3.0  ...    3.0      3.0   5.0    NaN\n",
              "232   NaN     NaN  7.49     4.1  ...    4.2      4.5   5.0    NaN\n",
              "289   NaN     NaN  6.99     4.0  ...    3.5      4.5   5.0    NaN\n",
              "14    NaN     NaN  6.25     3.0  ...    NaN      3.0   4.0    NaN\n",
              "83    NaN     NaN  7.49     4.0  ...    4.5      5.0   4.5    NaN\n",
              "42    4.5     4.1  6.99     4.0  ...    2.0      4.0   4.0    NaN\n",
              "157   NaN     NaN  7.00     3.0  ...    3.0      3.0   4.0    NaN\n",
              "52    4.5     4.7  7.99     3.5  ...    2.5      1.0   3.0    NaN\n",
              "30    4.0     4.4  6.60     3.5  ...    3.5      4.0   1.0    NaN\n",
              "\n",
              "[10 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CNgoC6X40U-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_case = [[3.6, 4.3, 6.7, 3.5, 19.4, 22., 0.7, 3.4, 3.7, 3.3, 3.5, \n",
        "             3.5, 3.2, 3.6, 3.5, 3.7]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AegMY_9l5Cf4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bc6186cc-3f4e-425c-c721-7147ed2518b3"
      },
      "source": [
        "linear_reg.predict(test_case)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.45175452])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glashDL8NmLp",
        "colab_type": "text"
      },
      "source": [
        "Now logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13i3N0v1z5ks",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "29a181a2-96ed-45bc-f10b-e829fd9d27da"
      },
      "source": [
        "X_train.mean()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yelp               3.897183\n",
              "Google             4.142254\n",
              "Cost               6.896781\n",
              "Hunger             3.445286\n",
              "Mass (g)                NaN\n",
              "Density (g/mL)          NaN\n",
              "Length            19.829886\n",
              "Circum            22.042241\n",
              "Volume             0.770920\n",
              "Tortilla           3.472315\n",
              "Temp               3.706360\n",
              "Meat               3.551215\n",
              "Fillings           3.519024\n",
              "Meat:filling       3.528870\n",
              "Uniformity         3.395946\n",
              "Salsa              3.324640\n",
              "Synergy            3.540203\n",
              "Wrap               3.955068\n",
              "Queso                   NaN\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUK8-0DUJMwm",
        "colab_type": "code",
        "outputId": "ed467817-820e-4cba-ab9f-9b7ceec173aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train_imputed, y_train)\n",
        "print('Validation Accuracy', log_reg.score(X_val_imputed, y_val))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8235294117647058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWwBG1RwyCng",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "7c8d23ba-760d-4d88-9da7-dbad3c4c847a"
      },
      "source": [
        "X_train_imputed, X_train"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[3.5       , 4.2       , 6.49      , ..., 4.        , 4.        ,\n",
              "         4.        ],\n",
              "        [3.5       , 3.3       , 5.45      , ..., 3.5       , 2.5       ,\n",
              "         5.        ],\n",
              "        [3.8971831 , 4.14225352, 4.85      , ..., 3.        , 3.        ,\n",
              "         5.        ],\n",
              "        ...,\n",
              "        [3.5       , 3.7       , 7.75      , ..., 2.2       , 3.3       ,\n",
              "         4.5       ],\n",
              "        [3.8971831 , 4.14225352, 7.75      , ..., 2.        , 2.        ,\n",
              "         4.        ],\n",
              "        [4.5       , 4.6       , 6.99      , ..., 3.32464029, 3.8       ,\n",
              "         2.        ]]),\n",
              "      Yelp  Google  Cost  Hunger  ...  Salsa  Synergy  Wrap  Queso\n",
              " 0     3.5     4.2  6.49     3.0  ...    4.0      4.0   4.0    NaN\n",
              " 1     3.5     3.3  5.45     3.5  ...    3.5      2.5   5.0    NaN\n",
              " 2     NaN     NaN  4.85     1.5  ...    3.0      3.0   5.0    NaN\n",
              " 3     NaN     NaN  5.25     2.0  ...    4.0      4.0   5.0    NaN\n",
              " 4     4.0     3.8  6.59     4.0  ...    2.5      4.5   4.0    NaN\n",
              " ..    ...     ...   ...     ...  ...    ...      ...   ...    ...\n",
              " 296   4.0     4.3  5.65     3.0  ...    3.0      2.0   4.5    NaN\n",
              " 297   NaN     NaN  5.49     3.0  ...    3.0      2.5   3.0    NaN\n",
              " 298   3.5     3.7  7.75     4.0  ...    2.2      3.3   4.5    NaN\n",
              " 299   NaN     NaN  7.75     4.0  ...    2.0      2.0   4.0    NaN\n",
              " 300   4.5     4.6  6.99     3.7  ...    NaN      3.8   2.0    NaN\n",
              " \n",
              " [298 rows x 19 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smzbM_MuN4fR",
        "colab_type": "code",
        "outputId": "a047ce4b-82dc-4546-d073-afdd36ae3bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Predictions look like this:\n",
        "log_reg.predict(X_val_imputed)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False,  True,  True, False, False,  True, False, False,\n",
              "        True,  True, False, False, False,  True, False, False,  True,\n",
              "        True,  True,  True,  True, False, False,  True,  True,  True,\n",
              "       False, False,  True,  True, False, False,  True, False, False,\n",
              "        True,  True, False, False, False,  True, False,  True,  True,\n",
              "       False, False, False, False, False, False, False,  True,  True,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False,  True,  True,  True,  True, False,  True,  True,\n",
              "        True,  True, False, False, False,  True,  True,  True,  True,\n",
              "        True, False,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxwnwt-yOZxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d482e160-d712-467c-b1cd-5b82c3a24a9d"
      },
      "source": [
        "# Find the math\n",
        "log_reg.coef_"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.79710014e-04, -1.57219640e+00,  2.01318113e-01,\n",
              "         1.03123980e-01, -2.19245539e-01, -4.49997092e-01,\n",
              "         1.57182263e+00,  5.73946380e-01,  3.25829976e-01,\n",
              "         1.11161482e+00,  9.58278844e-01,  9.04949469e-01,\n",
              "        -1.22955903e-02,  4.14216472e-01,  1.49935231e+00,\n",
              "         5.10509953e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f34XJCRzxm3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f2ce1e7-e596-40a3-828f-748597bb25aa"
      },
      "source": [
        "log_reg.intercept_"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.81167906])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBiWfCokxqe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sigmoid squishing function\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.e**(-x))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiT1BXXvx3Ld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da0381d0-eaed-4186-ea3e-568f77b6dc93"
      },
      "source": [
        "sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case))) # Chance target = 1, or that the burrito is considered 'Great'"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.15714008]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW4885lY0v5_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b5421d6-36d1-481c-c788-bc2a051bb70c"
      },
      "source": [
        "1 - sigmoid(log_reg.intercept_ + np.dot(log_reg.coef_, np.transpose(test_case))) # Chance target = 0, or burrito is not considered 'Great'"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.84285992]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CLuk3sdNTzu",
        "colab_type": "text"
      },
      "source": [
        "Check model's validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xo6KUHC9M-yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0abb465c-9d3f-4136-9eee-aec848eb3de8"
      },
      "source": [
        "# Set X features\n",
        "features = ['Yelp',\t'Google',\t'Cost',\t'Hunger', 'Length',\t'Circum',\t'Volume',\t\n",
        "            'Tortilla',\t'Temp',\t'Meat',\t'Fillings', 'Meat:filling',\t\n",
        "            'Uniformity',\t'Salsa',\t'Synergy',\t'Wrap']\n",
        "\n",
        "target = 'Great'\n",
        "\n",
        "X_train = train[features]\n",
        "y_train = train[target]\n",
        "X_val = val[features]\n",
        "y_val = val[target]\n",
        "\n",
        "X_train.shape, X_val.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((298, 16), (85, 16))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-d8di_SNuqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Important imports\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegressionCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bomqiW1pOAuM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b836379-4ae4-4d26-cbc8-9db752c47686"
      },
      "source": [
        "# One hot encoding\n",
        "encoder = ce.one_hot.OneHotEncoder(use_cat_names=True) # Instantiate one hot encoder\n",
        "X_train_enc = encoder.fit_transform(X_train) # Fit transform X_train\n",
        "X_val_enc = encoder.transform(X_val) # Transform X validation\n",
        "X_train_enc.shape, X_val_enc.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((298, 16), (85, 16))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPZDEoeQOZvP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "2adffb0b-3cee-4589-8a11-671896ede933"
      },
      "source": [
        "X_val_enc.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "      <td>20.5</td>\n",
              "      <td>0.77</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.50</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.5</td>\n",
              "      <td>21.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.6</td>\n",
              "      <td>4.2</td>\n",
              "      <td>3.75</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.50</td>\n",
              "      <td>3.9</td>\n",
              "      <td>21.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.74</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.20</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.90</td>\n",
              "      <td>4.0</td>\n",
              "      <td>20.5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0.72</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.80</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.99</td>\n",
              "      <td>3.5</td>\n",
              "      <td>18.5</td>\n",
              "      <td>22.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Yelp  Google  Cost  Hunger  ...  Uniformity  Salsa  Synergy  Wrap\n",
              "301   NaN     NaN  6.60     NaN  ...         5.0    1.5     3.50   4.5\n",
              "302   NaN     NaN  6.60     NaN  ...         4.6    4.2     3.75   5.0\n",
              "303   NaN     NaN  8.50     3.9  ...         4.0    4.3     4.20   5.0\n",
              "304   NaN     NaN  7.90     4.0  ...         4.5    4.0     3.80   4.8\n",
              "305   NaN     NaN  4.99     3.5  ...         3.0    2.0     2.00   4.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcSK5fRHOcQt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85e09158-c7be-40a2-b9eb-250fa9420d9a"
      },
      "source": [
        "# Impute NaN values\n",
        "imputer = SimpleImputer(strategy='mean') # Instantiate imputer\n",
        "X_train_imp = imputer.fit_transform(X_train_enc) # Fit transform X_train_encoder\n",
        "X_val_imp = imputer.transform(X_val_enc) # transform X validation encoder\n",
        "X_train_imp.shape, X_val_imp.shape"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((298, 16), (85, 16))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttCrD7WxO15K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "b9d79350-91c1-4ad2-8e2a-d666f82f24a9"
      },
      "source": [
        "X_val_imp"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.8971831 ,  4.14225352,  6.6       , ...,  1.5       ,\n",
              "         3.5       ,  4.5       ],\n",
              "       [ 3.8971831 ,  4.14225352,  6.6       , ...,  4.2       ,\n",
              "         3.75      ,  5.        ],\n",
              "       [ 3.8971831 ,  4.14225352,  8.5       , ...,  4.3       ,\n",
              "         4.2       ,  5.        ],\n",
              "       ...,\n",
              "       [ 4.        ,  4.5       , 11.5       , ...,  3.5       ,\n",
              "         4.        ,  2.        ],\n",
              "       [ 3.8971831 ,  4.14225352,  7.89      , ...,  3.5       ,\n",
              "         4.3       ,  4.5       ],\n",
              "       [ 3.8971831 ,  4.14225352,  7.89      , ...,  5.        ,\n",
              "         5.        ,  3.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJkPmdkRO38R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert those to dataframes\n",
        "X_train_imp = pd.DataFrame(X_train_imp, columns=X_train_enc.columns)\n",
        "X_val_imp = pd.DataFrame(X_val_imp, columns=X_val_enc.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQl-K4rsPJGH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "85aa1353-7af0-45ae-c0c4-f1e6f588c055"
      },
      "source": [
        "X_train_imp.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>4.200000</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.897183</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.897183</td>\n",
              "      <td>4.142254</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>19.829886</td>\n",
              "      <td>22.042241</td>\n",
              "      <td>0.77092</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Yelp    Google  Cost  Hunger  ...  Uniformity  Salsa  Synergy  Wrap\n",
              "0  3.500000  4.200000  6.49     3.0  ...         4.0    4.0      4.0   4.0\n",
              "1  3.500000  3.300000  5.45     3.5  ...         4.0    3.5      2.5   5.0\n",
              "2  3.897183  4.142254  4.85     1.5  ...         4.0    3.0      3.0   5.0\n",
              "3  3.897183  4.142254  5.25     2.0  ...         5.0    4.0      4.0   5.0\n",
              "4  4.000000  3.800000  6.59     4.0  ...         5.0    2.5      4.5   4.0\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMNxtJClPOaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run scaler; forces values onto the same scale\n",
        "scaler = StandardScaler() # Instantiate scaler\n",
        "X_train_sc = scaler.fit_transform(X_train_imp) # fit transform X train impute\n",
        "X_val_sc = scaler.transform(X_val_imp) # transform X validation impute"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBp_OfHsPnQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "ff6062dd-8cae-4ded-d73f-ef5a78724550"
      },
      "source": [
        "X_train_sc"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.71200227e+00,  3.20514492e-01, -3.39805235e-01, ...,\n",
              "         7.21245234e-01,  5.00993379e-01,  3.86864734e-02],\n",
              "       [-1.71200227e+00, -4.67482113e+00, -1.20857147e+00, ...,\n",
              "         1.87274062e-01, -1.13340089e+00,  8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -1.70978276e+00, ...,\n",
              "        -3.46697110e-01, -5.88602801e-01,  8.99678662e-01],\n",
              "       ...,\n",
              "       [-1.71200227e+00, -2.45467196e+00,  7.12738477e-01, ...,\n",
              "        -1.20105098e+00, -2.61723947e-01,  4.69182568e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  7.12738477e-01, ...,\n",
              "        -1.41463945e+00, -1.67819898e+00,  3.86864734e-02],\n",
              "       [ 2.59835806e+00,  2.54066366e+00,  7.78708410e-02, ...,\n",
              "         0.00000000e+00,  2.83074143e-01, -1.68329790e+00]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh1khH2pPovv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert those to dataframes\n",
        "X_train_sc = pd.DataFrame(X_train_sc, columns=X_train_enc.columns)\n",
        "X_val_sc = pd.DataFrame(X_val_sc, columns=X_val_enc.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51F89-_iP209",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "987d92a7-981a-48d6-e0b7-c73f1c08fbfc"
      },
      "source": [
        "X_train_sc.head()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Yelp</th>\n",
              "      <th>Google</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.712002e+00</td>\n",
              "      <td>3.205145e-01</td>\n",
              "      <td>-0.339805</td>\n",
              "      <td>-0.524307</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.593162</td>\n",
              "      <td>1.340696</td>\n",
              "      <td>-0.645992</td>\n",
              "      <td>-0.022447</td>\n",
              "      <td>0.458224</td>\n",
              "      <td>0.557478</td>\n",
              "      <td>0.721245</td>\n",
              "      <td>0.500993</td>\n",
              "      <td>0.038686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.712002e+00</td>\n",
              "      <td>-4.674821e+00</td>\n",
              "      <td>-1.208571</td>\n",
              "      <td>0.064423</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.849023</td>\n",
              "      <td>-0.213867</td>\n",
              "      <td>-1.231964</td>\n",
              "      <td>-1.202403</td>\n",
              "      <td>-1.486989</td>\n",
              "      <td>0.557478</td>\n",
              "      <td>0.187274</td>\n",
              "      <td>-1.133401</td>\n",
              "      <td>0.899679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.914185e-15</td>\n",
              "      <td>-4.929721e-15</td>\n",
              "      <td>-1.709783</td>\n",
              "      <td>-2.290496</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.593162</td>\n",
              "      <td>-1.768429</td>\n",
              "      <td>-1.231964</td>\n",
              "      <td>-0.612425</td>\n",
              "      <td>0.944528</td>\n",
              "      <td>0.557478</td>\n",
              "      <td>-0.346697</td>\n",
              "      <td>-0.588603</td>\n",
              "      <td>0.899679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.914185e-15</td>\n",
              "      <td>-4.929721e-15</td>\n",
              "      <td>-1.375642</td>\n",
              "      <td>-1.701766</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.593162</td>\n",
              "      <td>-1.768429</td>\n",
              "      <td>-0.060021</td>\n",
              "      <td>-0.612425</td>\n",
              "      <td>0.458224</td>\n",
              "      <td>1.480371</td>\n",
              "      <td>0.721245</td>\n",
              "      <td>0.500993</td>\n",
              "      <td>0.899679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.431779e-01</td>\n",
              "      <td>-1.899635e+00</td>\n",
              "      <td>-0.256270</td>\n",
              "      <td>0.653153</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.662698</td>\n",
              "      <td>1.340696</td>\n",
              "      <td>0.525950</td>\n",
              "      <td>-0.022447</td>\n",
              "      <td>0.944528</td>\n",
              "      <td>1.480371</td>\n",
              "      <td>-0.880668</td>\n",
              "      <td>1.045791</td>\n",
              "      <td>0.038686</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Yelp        Google      Cost  ...     Salsa   Synergy      Wrap\n",
              "0 -1.712002e+00  3.205145e-01 -0.339805  ...  0.721245  0.500993  0.038686\n",
              "1 -1.712002e+00 -4.674821e+00 -1.208571  ...  0.187274 -1.133401  0.899679\n",
              "2  1.914185e-15 -4.929721e-15 -1.709783  ... -0.346697 -0.588603  0.899679\n",
              "3  1.914185e-15 -4.929721e-15 -1.375642  ...  0.721245  0.500993  0.899679\n",
              "4  4.431779e-01 -1.899635e+00 -0.256270  ... -0.880668  1.045791  0.038686\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRwy95AAP3tw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "332368f3-154a-4a4a-9d06-d1b764de37a0"
      },
      "source": [
        "# Logistic Regression CV\n",
        "model = LogisticRegressionCV() # Instantiate \n",
        "model.fit(X_train_sc, y_train) # fit model with X train scaler and y train (target)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
              "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
              "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
              "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
              "                     solver='lbfgs', tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEAqcsenQQul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad4bd885-96df-4730-f6ca-423a04ec8b16"
      },
      "source": [
        "# Print validation score\n",
        "print(f'Validation Score: {model.score(X_val_sc, y_val)}')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Score: 0.8823529411764706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q29JHZmRC_v",
        "colab_type": "text"
      },
      "source": [
        "Let's look at our coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEOCeJC7QXHy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "5cd41829-91ac-4c59-ebfb-ec0b3fe1169e"
      },
      "source": [
        "coefs = pd.Series(model.coef_[0], X_train_sc.columns)\n",
        "coefs"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Yelp            0.093854\n",
              "Google         -0.004266\n",
              "Cost            0.195676\n",
              "Hunger          0.119757\n",
              "Length          0.042483\n",
              "Circum          0.000300\n",
              "Volume         -0.002146\n",
              "Tortilla        0.309644\n",
              "Temp            0.284428\n",
              "Meat            0.577196\n",
              "Fillings        0.579293\n",
              "Meat:filling    0.492726\n",
              "Uniformity      0.165661\n",
              "Salsa           0.257620\n",
              "Synergy         0.685466\n",
              "Wrap            0.102378\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnFlS11bRKHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a23521ee-f7aa-4f1f-a1d5-b6423c8a9ace"
      },
      "source": [
        "# Plot those\n",
        "coefs.sort_values().plot.barh();"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAD4CAYAAADYU1DBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTBGxn9VRi3h",
        "colab_type": "text"
      },
      "source": [
        "Get model's test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLgKrF3PRSAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c94b6e81-37dc-4faa-be1a-6b97eb912327"
      },
      "source": [
        "X_test = test[features] # X features\n",
        "X_test_enc = encoder.transform(X_test) # transform encoder using X_test\n",
        "X_test_imp = imputer.transform(X_test_enc) # Impute nan values\n",
        "X_test_scaled = scaler.transform(X_test_imp) # Scale imputed X_test so values are on same scale\n",
        "X_test_scaled"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.91418451e-15, -4.92972144e-15,  9.21576515e-01,\n",
              "         6.53153184e-01,  1.10673835e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  1.29062863e+00,  1.34069563e+00,\n",
              "         1.69789203e+00,  1.74748664e+00,  9.44527829e-01,\n",
              "         1.48037108e+00, -3.46697110e-01,  1.59058956e+00,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  2.95062401e-01,\n",
              "         6.53153184e-01,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  6.62698293e-01,  1.34069563e+00,\n",
              "         5.25949777e-01,  1.74748664e+00,  1.43083126e+00,\n",
              "        -3.65415944e-01, -3.46697110e-01,  5.00993379e-01,\n",
              "         8.99678662e-01],\n",
              "       [ 2.59835806e+00, -1.89963467e+00, -2.26111518e+00,\n",
              "        -5.24306577e-01,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00, -5.93162383e-01,  1.34069563e+00,\n",
              "        -1.81793472e+00, -1.79238058e+00,  4.58224401e-01,\n",
              "        -2.21120297e+00,  7.21245234e-01, -5.88602801e-01,\n",
              "         3.86864734e-02],\n",
              "       [-1.71200227e+00,  8.75551784e-01,  8.62243625e-02,\n",
              "         1.83061294e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  1.91855897e+00,  1.34069563e+00,\n",
              "         1.69789203e+00,  1.74748664e+00,  1.43083126e+00,\n",
              "         1.48037108e+00,  7.21245234e-01,  1.59058956e+00,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  1.33925259e+00,\n",
              "         6.53153184e-01,  7.35753563e-01,  1.13542854e+00,\n",
              "         1.41955406e+00,  6.62698293e-01,  3.04320697e-01,\n",
              "        -6.45992473e-01, -2.24469694e-02, -2.45959617e+00,\n",
              "        -1.28830946e+00, -3.46697110e-01, -5.88602801e-01,\n",
              "        -2.54429009e+00],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  2.53294793e-01,\n",
              "        -5.24306577e-01,  2.93651079e+00,  5.12319325e-01,\n",
              "         2.18131939e+00,  6.62698293e-01,  1.34069563e+00,\n",
              "         5.25949777e-01, -6.12424838e-01, -5.14382455e-01,\n",
              "        -3.65415944e-01,  7.21245234e-01, -5.88602801e-01,\n",
              "         3.86864734e-02],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.57481311e-01,\n",
              "        -5.24306577e-01,  1.06965784e-01,  7.45985282e-01,\n",
              "         6.57788736e-01,  3.47679550e-02,  1.34069563e+00,\n",
              "         8.77532452e-01, -2.24469694e-02,  1.43083126e+00,\n",
              "         5.57477567e-01, -3.46697110e-01,  2.83074143e-01,\n",
              "        -1.68329790e+00],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.57481311e-01,\n",
              "         6.44233034e-02, -1.46500366e+00,  1.52487180e+00,\n",
              "         2.76906074e-01,  6.62698293e-01,  8.22508165e-01,\n",
              "         1.69789203e+00,  1.15750877e+00,  1.43083126e+00,\n",
              "         5.57477567e-01,  7.21245234e-01,  1.04579147e+00,\n",
              "         3.86864734e-02],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.57481311e-01,\n",
              "        -1.70176634e+00, -5.21821995e-01,  1.91431507e+00,\n",
              "         1.32433340e+00, -1.84902306e+00, -2.13866771e-01,\n",
              "         1.11192090e+00,  5.67530899e-01,  4.58224401e-01,\n",
              "        -1.28830946e+00, -3.46697110e-01,  5.00993379e-01,\n",
              "        -1.68329790e+00],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  1.74857514e+00,\n",
              "         6.53153184e-01,  3.25090468e+00,  7.45985282e-01,\n",
              "         2.65742272e+00,  1.29062863e+00,  8.22508165e-01,\n",
              "         5.25949777e-01,  5.67530899e-01, -5.14382455e-01,\n",
              "         5.57477567e-01,  1.87274062e-01,  5.00993379e-01,\n",
              "        -8.22305716e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  1.74857514e+00,\n",
              "         6.53153184e-01,  2.62211690e+00, -3.29012411e-02,\n",
              "         1.41955406e+00,  1.29062863e+00,  1.34069563e+00,\n",
              "        -6.00213478e-02,  5.67530899e-01,  4.58224401e-01,\n",
              "         5.57477567e-01,  0.00000000e+00, -1.13340089e+00,\n",
              "        -2.11379400e+00],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.57481311e-01,\n",
              "         6.44233034e-02, -1.77939755e+00, -4.22344502e-01,\n",
              "        -1.34184524e+00,  6.62698293e-01,  8.22508165e-01,\n",
              "        -6.00213478e-02, -6.12424838e-01,  9.44527829e-01,\n",
              "        -3.65415944e-01, -3.46697110e-01, -1.13340089e+00,\n",
              "        -1.25280181e+00],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  5.03900439e-01,\n",
              "         6.53153184e-01, -1.15060977e+00, -3.29012411e-02,\n",
              "        -7.70521249e-01,  6.62698293e-01,  3.04320697e-01,\n",
              "        -6.00213478e-02,  8.03522047e-01,  9.44527829e-01,\n",
              "         8.34345620e-01, -3.46697110e-01,  5.00993379e-01,\n",
              "         4.69182568e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.57481311e-01,\n",
              "        -5.24306577e-01,  1.06965784e-01, -1.20123103e+00,\n",
              "        -9.60962580e-01, -1.84902306e+00,  1.34069563e+00,\n",
              "         1.11192090e+00, -2.24469694e-02,  9.44527829e-01,\n",
              "         1.01892432e+00, -8.80668281e-01, -4.38047113e-02,\n",
              "        -2.11379400e+00],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.57481311e-01,\n",
              "         1.83061294e+00,  1.36454134e+00, -2.36956081e+00,\n",
              "        -1.34184524e+00,  6.62698293e-01,  8.22508165e-01,\n",
              "        -6.00213478e-02,  5.67530899e-01,  4.58224401e-01,\n",
              "         9.60308113e-02,  7.21245234e-01,  5.00993379e-01,\n",
              "        -3.91809621e-01],\n",
              "       [-1.71200227e+00, -1.89963467e+00,  1.33925259e+00,\n",
              "        -2.88814625e-01, -1.15060977e+00,  7.45985282e-01,\n",
              "        -1.03976589e-01,  4.11526158e-01,  3.04320697e-01,\n",
              "         5.25949777e-01,  5.67530899e-01,  2.63703030e-01,\n",
              "         3.74146018e-03,  1.04162794e+00,  5.00993379e-01,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  2.17460474e+00,\n",
              "        -5.24306577e-01, -5.21821995e-01,  1.52487180e+00,\n",
              "         9.43450733e-01,  3.47679550e-02, -7.32054239e-01,\n",
              "         2.91561327e-01,  5.67530899e-01,  2.63703030e-01,\n",
              "         1.01892432e+00,  1.25521641e+00,  5.00993379e-01,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  1.33925259e+00,\n",
              "        -2.88814625e-01, -2.07428106e-01, -4.22344502e-01,\n",
              "        -4.84859252e-01,  3.47679550e-02, -2.80480411e+00,\n",
              "        -6.45992473e-01, -6.12424838e-01, -1.25339712e-01,\n",
              "         5.57477567e-01,  1.25521641e+00, -5.88602801e-01,\n",
              "         3.86864734e-02],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  1.33925259e+00,\n",
              "        -5.24306577e-01, -1.15060977e+00, -2.36956081e+00,\n",
              "        -2.38927257e+00, -5.93162383e-01, -1.25024171e+00,\n",
              "        -6.00213478e-02, -6.12424838e-01, -2.45959617e+00,\n",
              "        -2.21120297e+00,  7.21245234e-01, -4.38047113e-02,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  7.78708410e-02,\n",
              "         6.53153184e-01, -1.15060977e+00,  7.45985282e-01,\n",
              "        -1.03976589e-01,  3.47679550e-02, -7.32054239e-01,\n",
              "        -4.11604023e-01, -3.76433691e-01, -3.19861083e-01,\n",
              "         5.57477567e-01, -3.46697110e-01, -1.13340089e+00,\n",
              "         4.69182568e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.57481311e-01,\n",
              "         6.44233034e-02, -2.07428106e-01, -8.11787764e-01,\n",
              "        -8.65741914e-01, -1.22109272e+00, -7.32054239e-01,\n",
              "         5.25949777e-01, -2.24469694e-02, -1.00068588e+00,\n",
              "        -8.26862700e-01, -2.63144067e-02, -5.88602801e-01,\n",
              "         3.86864734e-02],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.57481311e-01,\n",
              "         6.44233034e-02, -8.36215885e-01,  1.52487180e+00,\n",
              "         7.53009402e-01,  6.62698293e-01,  3.04320697e-01,\n",
              "         1.11192090e+00,  5.67530899e-01,  9.44527829e-01,\n",
              "         1.48037108e+00,  7.21245234e-01,  5.00993379e-01,\n",
              "         0.00000000e+00],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  2.58392730e+00,\n",
              "         1.83061294e+00,  1.06965784e-01, -3.29012411e-02,\n",
              "        -8.75592328e-03,  6.62698293e-01,  3.04320697e-01,\n",
              "        -6.45992473e-01, -6.12424838e-01,  1.43083126e+00,\n",
              "         9.60308113e-02,  0.00000000e+00, -5.88602801e-01,\n",
              "         4.69182568e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  2.58392730e+00,\n",
              "         6.53153184e-01,  1.06965784e-01, -3.29012411e-02,\n",
              "        -8.75592328e-03,  1.91855897e+00,  1.34069563e+00,\n",
              "        -6.45992473e-01, -6.12424838e-01,  4.58224401e-01,\n",
              "         5.57477567e-01, -1.41463945e+00,  5.00993379e-01,\n",
              "        -8.22305716e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  4.12011702e-01,\n",
              "         6.53153184e-01,  2.62211690e+00, -8.11787764e-01,\n",
              "         6.57788736e-01,  1.91855897e+00,  3.04320697e-01,\n",
              "         5.25949777e-01, -6.12424838e-01,  4.58224401e-01,\n",
              "         1.48037108e+00,  7.21245234e-01,  5.00993379e-01,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  4.12011702e-01,\n",
              "         1.24188306e+00,  7.35753563e-01,  3.56542020e-01,\n",
              "         7.53009402e-01,  3.47679550e-02,  8.22508165e-01,\n",
              "         5.25949777e-01, -2.24469694e-02, -1.48698931e+00,\n",
              "        -2.21120297e+00,  1.87274062e-01, -4.38047113e-02,\n",
              "         3.86864734e-02],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  4.12011702e-01,\n",
              "         6.53153184e-01,  1.36454134e+00, -1.59067429e+00,\n",
              "        -6.75300583e-01, -5.93162383e-01,  1.34069563e+00,\n",
              "        -5.20446908e-16, -6.12424838e-01, -4.31924210e-16,\n",
              "         5.57477567e-01,  0.00000000e+00, -5.88602801e-01,\n",
              "         3.86864734e-02],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  9.21576515e-01,\n",
              "         6.53153184e-01,  1.05014745e+00,  1.52487180e+00,\n",
              "         2.08609872e+00,  1.91855897e+00,  1.34069563e+00,\n",
              "         1.69789203e+00,  1.15750877e+00,  1.43083126e+00,\n",
              "         1.48037108e+00,  1.78918758e+00,  1.59058956e+00,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  9.21576515e-01,\n",
              "         6.53153184e-01,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00,  6.62698293e-01,  8.22508165e-01,\n",
              "        -6.00213478e-02,  5.67530899e-01,  4.58224401e-01,\n",
              "         1.48037108e+00,  1.46880487e+00,  5.00993379e-01,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -1.16680387e+00,\n",
              "        -1.70176634e+00, -5.21821995e-01,  7.45985282e-01,\n",
              "         2.76906074e-01,  1.29062863e+00,  1.34069563e+00,\n",
              "         1.69789203e+00, -2.24469694e-02,  4.58224401e-01,\n",
              "         1.01892432e+00,  7.21245234e-01,  1.48162994e+00,\n",
              "         4.69182568e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -1.22613675e-01,\n",
              "        -5.24306577e-01, -5.21821995e-01,  2.30375833e+00,\n",
              "         1.60999539e+00, -5.93162383e-01,  3.04320697e-01,\n",
              "         5.25949777e-01, -6.12424838e-01,  4.58224401e-01,\n",
              "         5.57477567e-01, -3.46697110e-01, -5.88602801e-01,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.49127789e-01,\n",
              "        -5.24306577e-01, -1.46500366e+00, -4.22344502e-01,\n",
              "        -1.24662458e+00,  6.62698293e-01,  3.04320697e-01,\n",
              "         1.11192090e+00,  5.67530899e-01, -5.14382455e-01,\n",
              "        -3.65415944e-01,  1.25521641e+00,  5.00993379e-01,\n",
              "         4.69182568e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  8.38041299e-01,\n",
              "        -1.70176634e+00, -1.77939755e+00, -3.29012411e-02,\n",
              "        -1.15140391e+00,  1.29062863e+00, -7.32054239e-01,\n",
              "         5.25949777e-01,  1.15750877e+00, -1.00068588e+00,\n",
              "         9.60308113e-02,  7.21245234e-01,  1.59058956e+00,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.49127789e-01,\n",
              "        -2.87922610e+00, -1.77939755e+00, -1.20123103e+00,\n",
              "        -1.91316924e+00,  1.91855897e+00,  3.04320697e-01,\n",
              "        -6.00213478e-02,  1.04801122e-15,  4.58224401e-01,\n",
              "         5.57477567e-01, -1.41463945e+00, -1.67819898e+00,\n",
              "         8.99678662e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -7.49127789e-01,\n",
              "         6.53153184e-01, -5.21821995e-01,  3.08264485e+00,\n",
              "         2.37176072e+00,  6.62698293e-01,  1.34069563e+00,\n",
              "        -5.20446908e-16, -2.24469694e-02,  4.58224401e-01,\n",
              "         5.57477567e-01,  1.78918758e+00,  5.00993379e-01,\n",
              "        -8.22305716e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  8.38041299e-01,\n",
              "        -5.24306577e-01,  1.06965784e-01, -3.29012411e-02,\n",
              "        -8.75592328e-03,  6.62698293e-01,  3.04320697e-01,\n",
              "         5.25949777e-01,  2.13544178e-01, -5.14382455e-01,\n",
              "        -1.28830946e+00,  1.87274062e-01,  5.00993379e-01,\n",
              "         4.69182568e-01],\n",
              "       [ 1.91418451e-15, -4.92972144e-15,  8.38041299e-01,\n",
              "        -5.24306577e-01,  1.67893523e+00,  1.91431507e+00,\n",
              "         2.84786405e+00,  1.91855897e+00, -1.76842918e+00,\n",
              "         1.69789203e+00,  1.74748664e+00,  1.43083126e+00,\n",
              "        -1.28830946e+00,  1.78918758e+00,  1.59058956e+00,\n",
              "        -1.68329790e+00],\n",
              "       [ 1.91418451e-15, -4.92972144e-15, -1.16680387e+00,\n",
              "         6.44233034e-02, -1.77939755e+00, -5.78121807e-01,\n",
              "        -1.53228657e+00, -5.93162383e-01,  1.34069563e+00,\n",
              "         8.77532452e-01,  5.67530899e-01,  1.33357057e+00,\n",
              "         3.72898865e-01, -3.46697110e-01,  1.04579147e+00,\n",
              "         3.86864734e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8Xl2fuvR-yf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d072b342-d08e-44e2-803e-e607a3017faa"
      },
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "y_pred"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False,  True, False, False,  True,  True, False,\n",
              "        True,  True, False,  True, False,  True,  True,  True, False,\n",
              "       False, False, False,  True, False,  True,  True, False, False,\n",
              "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
              "        True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDP8reRoSHMB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "0e7c40e8-424b-49a3-db0d-6f24d9df3972"
      },
      "source": [
        "test_answers = np.array(test['Great'])\n",
        "test_answers"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True, False, False,  True, False,  True,  True,  True, False,\n",
              "        True, False, False, False,  True,  True,  True, False, False,\n",
              "       False, False, False,  True,  True,  True,  True, False, False,\n",
              "        True,  True,  True,  True,  True,  True, False,  True, False,\n",
              "        True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMN15Ww9SN9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4800489a-a5e3-4316-e07f-b1690bdcf521"
      },
      "source": [
        "test_counts = pd.Series(test_answers == y_pred).value_counts()\n",
        "test_counts"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     29\n",
              "False     9\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afGjGn19Twb3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65ee4654-e8e0-440c-e2ae-a93f6740633d"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38, 59)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acyr9UwFUetR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a4aa227-5869-4623-fcdb-437b87916737"
      },
      "source": [
        "# There are 29 correct answers and 9 incorrect answers. This gives us a test accuracy of:\n",
        "test_counts[1] / test.shape[0]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7631578947368421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlLYQgEPUt2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have a 76.3% test accuracy using this model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25OvOczPU6wO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}