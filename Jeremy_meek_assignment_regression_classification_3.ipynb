{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jeremy_meek_assignment_regression_classification_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Distortedlogic/DS-Unit-2-Regression-Classification/blob/master/Jeremy_meek_assignment_regression_classification_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IXUfiQ2UKj6",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Regression & Classification, Module 3\n",
        "\n",
        "## Assignment\n",
        "\n",
        "We're going back to our other **New York City** real estate dataset. Instead of predicting apartment rents, you'll predict property sales prices.\n",
        "\n",
        "But not just for condos in Tribeca...\n",
        "\n",
        "Instead, predict property sales prices for **One Family Dwellings** (`BUILDING_CLASS_CATEGORY` == `'01 ONE FAMILY DWELLINGS'`) using a subset of the data where the **sale price was more than \\\\$100 thousand and less than $2 million.** \n",
        "\n",
        "The [NYC Department of Finance](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page) has a glossary of property sales terms and NYC Building Class Code Descriptions. The data comes from the [NYC OpenData](https://data.cityofnewyork.us/browse?q=NYC%20calendar%20sales) portal.\n",
        "\n",
        "\n",
        "- [ ] Do train/test split. Use data from January — March 2019 to train. Use data from April 2019 to test.\n",
        "- [ ] Do exploratory visualizations with Seaborn.\n",
        "- [ ] Do one-hot encoding of categorical features.\n",
        "- [ ] Do feature selection with `SelectKBest`.\n",
        "- [ ] Fit a linear regression model with multiple features.\n",
        "- [ ] Get mean absolute error for the test set.\n",
        "- [ ] As always, commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Try [`RidgeCV`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) instead of Linear Regression, especially if your errors blow up! Watch [Aaron Gallant's 9 minute video on Ridge Regression](https://www.youtube.com/watch?v=XK5jkedy17w) to learn more.\n",
        "- [ ] Do [feature scaling](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
        "- [ ] Learn more about feature selection:\n",
        "    - [\"Permutation importance\"](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "    - [scikit-learn's User Guide for Feature Selection](https://scikit-learn.org/stable/modules/feature_selection.html)\n",
        "    - [mlxtend](http://rasbt.github.io/mlxtend/) library\n",
        "    - scikit-learn-contrib libraries: [boruta_py](https://github.com/scikit-learn-contrib/boruta_py) & [stability-selection](https://github.com/scikit-learn-contrib/stability-selection)\n",
        "    - [_Feature Engineering and Selection_](http://www.feat.engineering/) by Kuhn & Johnson.\n",
        "- [ ] Try [statsmodels](https://www.statsmodels.org/stable/index.html) if you’re interested in more inferential statistical approach to linear regression and feature selection, looking at p values and 95% confidence intervals for the coefficients.\n",
        "- [ ] Read [_An Introduction to Statistical Learning_](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Chapters 1-3, for more math & theory, but in an accessible, readable way (without an excessive amount of formulas or academic pre-requisites).\n",
        "(That book is good regardless of whether your cultural worldview is inferential statistics or predictive machine learning)\n",
        "- [ ] Read Leo Breiman's paper, [\"Statistical Modeling: The Two Cultures\"](https://projecteuclid.org/download/pdf_1/euclid.ss/1009213726)\n",
        "- [ ] Try [scikit-learn pipelines](https://scikit-learn.org/stable/modules/compose.html):\n",
        "\n",
        "> Pipeline can be used to chain multiple estimators into one. This is useful as there is often a fixed sequence of steps in processing the data, for example feature selection, normalization and classification. Pipeline serves multiple purposes here:\n",
        "\n",
        "> - **Convenience and encapsulation.** You only have to call fit and predict once on your data to fit a whole sequence of estimators.\n",
        "> - **Joint parameter selection.** You can grid search over parameters of all estimators in the pipeline at once.\n",
        "> - **Safety.** Pipelines help avoid leaking statistics from your test data into the trained model in cross-validation, by ensuring that the same samples are used to train the transformers and predictors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9eSnDYhUGD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python packages:\n",
        "    # category_encoders, version >= 2.0\n",
        "    # pandas-profiling, version >= 2.0\n",
        "    # plotly, version >= 4.0\n",
        "    !pip install --upgrade category_encoders pandas-profiling plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Regression-Classification.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipBYS77PUwNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Ignore this Numpy warning when using Plotly Express:\n",
        "# FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3WyNB5ucx3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy as sp\n",
        "import category_encoders as ce\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.linear_model import LinearRegression, RidgeCV\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.feature_selection import f_regression, SelectKBest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import time\n",
        "from math import sqrt\n",
        "\n",
        "import pandas_profiling\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJBD4ruICm1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read New York City property sales data\n",
        "odf = pd.read_csv('../data/condos/NYC_Citywide_Rolling_Calendar_Sales.csv')\n",
        "\n",
        "# Change column names: replace spaces with underscores\n",
        "odf.columns = [col.replace(' ', '_') for col in odf]\n",
        "\n",
        "# SALE_PRICE was read as strings.\n",
        "# Remove symbols, convert to integer\n",
        "odf['SALE_PRICE'] = (\n",
        "    odf['SALE_PRICE']\n",
        "    .str.replace('$','')\n",
        "    .str.replace('-','')\n",
        "    .str.replace(',','')\n",
        "    .astype(int)\n",
        ")\n",
        "\n",
        "fam = (odf['BUILDING_CLASS_CATEGORY'] == '01 ONE FAMILY DWELLINGS')\n",
        "price_range = (100_000<odf['SALE_PRICE']) & (odf['SALE_PRICE']<2_000_000)\n",
        "odf = odf[fam & price_range]\n",
        "\n",
        "odf['LAND_SQUARE_FEET'] = odf['LAND_SQUARE_FEET'].apply(lambda s: s.replace(',', '')).astype(int)\n",
        "odf['ZIP_CODE'] = odf['ZIP_CODE'].astype(str)\n",
        "\n",
        "toss = ['APARTMENT_NUMBER', 'ZIP_CODE', 'EASE-MENT', 'TAX_CLASS_AT_TIME_OF_SALE', 'BUILDING_CLASS_CATEGORY', 'ADDRESS']\n",
        "odf = odf.drop(toss, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82md-3wJ7GiM",
        "colab_type": "text"
      },
      "source": [
        "#Custom Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zxuAvl4aidL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def timeit(method):\n",
        "  '''\n",
        "  Decorator to time how long a function runs\n",
        "  '''\n",
        "  def timed(*args, **kw):\n",
        "      def _pretty(value):\n",
        "          '''From seconds to Days;Hours:Minutes;Seconds'''\n",
        "\n",
        "          valueD = (((value/365)/24)/60)\n",
        "          Days = int(valueD)\n",
        "\n",
        "          valueH = (valueD-Days)*365\n",
        "          Hours = int(valueH)\n",
        "\n",
        "          valueM = (valueH - Hours)*24\n",
        "          Minutes = int(valueM)\n",
        "\n",
        "          valueS = (valueM - Minutes)*60\n",
        "          Seconds = int(valueS)\n",
        "\n",
        "          return str(Days)+\"D:\"+str(Hours)+\"H:\"+str(Minutes)+\"M:\"+str(Seconds)+\"S\"\n",
        "\n",
        "      ts = time.time()\n",
        "      result = method(*args, **kw)\n",
        "      te = time.time()\n",
        "      print(f'\\n{method.__name__} took {_pretty(te-ts)}\\n')\n",
        "      return result\n",
        "  return timed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXhBF8-Ozn8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@timeit\n",
        "def calc_best_features(dataframe, target):\n",
        "  '''\n",
        "  Calculate the best features to use with linear regression.\n",
        "\n",
        "  Parameters:\n",
        "  dataframe - Your dataframe with target as a feature.\n",
        "  target - What you want to predict.\n",
        "\n",
        "  Return:\n",
        "  Dictionary:\n",
        "   - Different scoring metrics of the best model.\n",
        "   - Number of features\n",
        "   - The best features.\n",
        "  '''\n",
        "\n",
        "  kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "  model = LinearRegression()\n",
        "\n",
        "  features = [f for f in dataframe.columns if f not in target]\n",
        "  stats = {\n",
        "        'mse': np.inf,\n",
        "    }\n",
        "    \n",
        "  for train_index, test_index in kf.split(dataframe[features]):\n",
        "    train, test = dataframe.iloc[train_index], dataframe.iloc[test_index]\n",
        "\n",
        "    for k in range(1, len(features)+1):\n",
        "        \n",
        "        selector = SelectKBest(score_func=f_regression, k=k)\n",
        "        X_train_selected = selector.fit_transform(train[features], train[target])\n",
        "        X_test_selected = selector.transform(test[features])\n",
        "        \n",
        "        model.fit(X_train_selected, train[target])\n",
        "        y_pred = model.predict(X_test_selected)\n",
        "        \n",
        "        if mean_squared_error(test[target], y_pred) < stats['mse']:\n",
        "          stats['mse'] = mean_squared_error(test[target], y_pred)\n",
        "          stats['rmse'] = sqrt(mean_squared_error(test[target], y_pred))\n",
        "          stats['r2'] = r2_score(test[target], y_pred)\n",
        "          stats['mae'] = mean_absolute_error(test[target], y_pred)\n",
        "          stats['num_features'] = k\n",
        "\n",
        "          selected_mask = selector.get_support()\n",
        "          stats['features'] = list(train[features].columns[selected_mask])\n",
        "          stats['exclude_features'] = list(train[features].columns[~selected_mask])\n",
        "\n",
        "  return stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5JFmjoZf1Af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_linear_model(dataframe, target):\n",
        "  '''\n",
        "  Builds a linear regression model. Metrics are calculated on a hold out set.\n",
        "\n",
        "  Parameters:\n",
        "  dataframe - Your dataframe with target as a feature.\n",
        "  target - What you want to predict.\n",
        "\n",
        "  Return:\n",
        "  Dictionary:\n",
        "   - Different scoring metrics of the best model.\n",
        "   - The Model\n",
        "  '''\n",
        "\n",
        "  kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
        "  model = LinearRegression()\n",
        "\n",
        "  features = [f for f in dataframe.columns if f not in target]\n",
        "  stats = {\n",
        "        'mse': np.inf,\n",
        "    }\n",
        "  \n",
        "  build_set, holdout_set = train_test_split(dataframe, test_size=0.1, shuffle=True)\n",
        "    \n",
        "  for train_index, test_index in kf.split(build_set[features]):\n",
        "    train, test = build_set.iloc[train_index], build_set.iloc[test_index]\n",
        "        \n",
        "    model.fit(train[features], train[target])\n",
        "    y_pred = model.predict(test[features])\n",
        "    \n",
        "    if mean_squared_error(test[target], y_pred) < stats['mse']:\n",
        "      stats['mse'] = mean_squared_error(test[target], y_pred)\n",
        "      best_model = model\n",
        "\n",
        "      # stats['rmse'] = sqrt(mean_squared_error(test[target], y_pred))\n",
        "      # stats['r2'] = r2_score(test[target], y_pred)\n",
        "      # stats['mae'] = mean_absolute_error(test[target], y_pred)\n",
        "      # stats['model'] = best_model\n",
        "\n",
        "  holdout_pred = best_model.predict(holdout_set[features])\n",
        "\n",
        "  stats['mse'] = mean_squared_error(holdout_set[target], holdout_pred)\n",
        "  stats['rmse'] = sqrt(mean_squared_error(holdout_set[target], holdout_pred))\n",
        "  stats['r2'] = r2_score(holdout_set[target], holdout_pred)\n",
        "  stats['mae'] = mean_absolute_error(holdout_set[target], holdout_pred)\n",
        "  stats['model'] = best_model\n",
        "\n",
        "  return stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMAyqGHUM2X7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_ridge_model(dataframe, target):\n",
        "  '''\n",
        "  Builds a ridge regression model. Metrics are calculated on a hold out set.\n",
        "\n",
        "  Parameters:\n",
        "  dataframe - Your dataframe with target as a feature.\n",
        "  target - What you want to predict.\n",
        "\n",
        "  Return:\n",
        "  Dictionary:\n",
        "   - Different scoring metrics of the best model.\n",
        "   - alpha\n",
        "   - The Model\n",
        "  '''\n",
        "\n",
        "  features = [f for f in dataframe.columns if f not in target]\n",
        "  stats = {\n",
        "        'mse': np.inf,\n",
        "    }\n",
        "  \n",
        "  build_set, holdout_set = train_test_split(dataframe, test_size=0.1, random_state=42, shuffle=True)\n",
        "\n",
        "  ridge = RidgeCV(alphas = [i/10 for i in range(1, 20, 1)], cv = 10)\n",
        "  ridge.fit(build_set[features], build_set[target])\n",
        "\n",
        "  y_pred = ridge.predict(holdout_set[features])\n",
        "\n",
        "  stats['mse'] = mean_squared_error(holdout_set[target], y_pred)\n",
        "  stats['rmse'] = sqrt(mean_squared_error(holdout_set[target], y_pred))\n",
        "  stats['r2'] = r2_score(holdout_set[target], y_pred)\n",
        "  stats['mae'] = mean_absolute_error(holdout_set[target], y_pred)\n",
        "  stats['model'] = ridge\n",
        "  stats['alpha'] = ridge.alpha_\n",
        "\n",
        "  return stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ABP7XtndQ3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = odf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp7GNrmknUUD",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moqLuRuq4e-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "newest_time = pd.to_datetime(df['SALE_DATE']).max()\n",
        "df['days_old'] = (pd.to_datetime(df['SALE_DATE'])-newest_time).apply(lambda t: abs(t.days))\n",
        "df = df.drop('SALE_DATE', axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALUHUWafRxfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = df\n",
        "scaler = StandardScaler()\n",
        "to_scale = list(set(list(temp.select_dtypes(exclude=['object']))) - set(['SALE_PRICE']))\n",
        "temp[to_scale] = scaler.fit_transform(temp[to_scale])\n",
        "scaled = temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asg2xLyL-C9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = ce.OneHotEncoder()\n",
        "to_encode = list(scaled.select_dtypes(include=['object']))\n",
        "encoded = le.fit_transform(scaled[to_encode])\n",
        "encoded_df = pd.concat([scaled, encoded], axis=1).drop(to_encode, axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urs-gU7SMrR9",
        "colab_type": "text"
      },
      "source": [
        "#Build Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfu2EBpXeQmF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3f4d911-2301-4caa-ed26-3883969e1f55"
      },
      "source": [
        "mean_squared_error([encoded_df['SALE_PRICE'].mean() for _ in range(0,len(encoded_df))], encoded_df['SALE_PRICE'])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85816118571.50015"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBpS9I_OiHDX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "079db96d-8483-4626-dd58-daf4e9b14bc6"
      },
      "source": [
        "pp.pprint(build_linear_model(encoded_df, ['SALE_PRICE']))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'mae': 125652.99050632911,\n",
            "    'model': LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
            "    'mse': 32101293782.363926,\n",
            "    'r2': 0.5300170024915367,\n",
            "    'rmse': 179168.33922979786}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewBOKNfCih6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "669d8500-e4fd-49ff-9bcb-0d6f49b61347"
      },
      "source": [
        "pp.pprint(build_ridge_model(encoded_df, ['SALE_PRICE']))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{   'alpha': 0.8,\n",
            "    'mae': 133114.370822912,\n",
            "    'model': RidgeCV(alphas=array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
            "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9]),\n",
            "        cv=10, fit_intercept=True, gcv_mode=None, normalize=False, scoring=None,\n",
            "        store_cv_values=False),\n",
            "    'mse': 38368434505.96907,\n",
            "    'r2': 0.5395847582249651,\n",
            "    'rmse': 195878.6218707112}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UffTj660MqwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}