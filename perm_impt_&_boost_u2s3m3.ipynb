{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "perm impt & boost_u2s3m3.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LambdaTheda/DS-Unit-2-Linear-Models/blob/master/perm_impt_%26_boost_u2s3m3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U2ha9OWxf0jw"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 3*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "# Permutation & Boosting\n",
        "\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wMejJg0w8v76"
      },
      "source": [
        "### Setup\n",
        "\n",
        "Run the code cell below. You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab.\n",
        "\n",
        "Libraries:\n",
        "\n",
        "- category_encoders\n",
        "- [**eli5**](https://eli5.readthedocs.io/en/latest/)\n",
        "- matplotlib\n",
        "- numpy\n",
        "- pandas\n",
        "- scikit-learn\n",
        "- [**xgboost**](https://xgboost.readthedocs.io/en/latest/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFQMky3CYih-",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Applied-Modeling/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install eli5\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50Y4S6ULKDa_",
        "colab_type": "text"
      },
      "source": [
        "We'll go back to Tanzania Waterpumps for this lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z-TExplb_Slf",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rhg8PQKt_jzP",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8lB4z5l_eml",
        "outputId": "8ee45c49-6c41-4461-c307-72f8c87080fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxhmJFxvKDbM",
        "colab_type": "text"
      },
      "source": [
        "# Get permutation importances for model interpretation and feature selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OrNwkCXKDbN",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDhlRESkKDbP",
        "colab_type": "text"
      },
      "source": [
        "Default Feature Importances are fast, but Permutation Importances may be more accurate.\n",
        "\n",
        "These links go deeper with explanations and examples:\n",
        "\n",
        "- Permutation Importances\n",
        "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "- (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7HOayKBOYiit"
      },
      "source": [
        "There are three types of feature importances:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4bRhsxENYiiu"
      },
      "source": [
        "### 1. (Default) Feature Importances\n",
        "\n",
        "Fastest, good for first estimates, but be aware:\n",
        "\n",
        "\n",
        "\n",
        ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
        "\n",
        "\n",
        " \n",
        " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNVm6f7mYiiu",
        "outputId": "992e55cb-eefe-430f-cf82-8558733ff0c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArYAAAJOCAYAAABCwkSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRvmFtOoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y8HzLcCBYiiv"
      },
      "source": [
        "### 2. Drop-Column Importance\n",
        "\n",
        "The best in theory, but too slow in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQAOlERnYiiw",
        "outputId": "ebe0037c-27cc-41e9-85d7-49630abdb03e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "column  = 'payment'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "d\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without payment: 0.8114478114478114\n",
            "Validation Accuracy with payment: 0.8135521885521886\n",
            "Drop-Column Importance for payment: 0.002104377104377164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vu39wGkYiix"
      },
      "source": [
        "### 3. Permutation Importance\n",
        "\n",
        "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
        "\n",
        "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
        "\n",
        "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
        ">\n",
        "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
        ">\n",
        ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
        ">\n",
        ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYCiEx7zYiiy"
      },
      "source": [
        "### Do-It-Yourself way, for intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TksOf_n2Yiiy",
        "outputId": "5b72c359-da7c-4561-f01c-33cb429cb8ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# BEFORE: Sequence of the feature to be permuted\n",
        "feature = 'quantity'\n",
        "X_val[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     insufficient\n",
              "47666    insufficient\n",
              "2538           enough\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Aeb0o2iWGBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PERMUTE\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghwf8575WMBj",
        "colab_type": "code",
        "outputId": "26ad4f9e-e741-4b2b-b6fa-cd17fe413f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# AFTER: Sequence has changed\n",
        "X_val_permuted[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290           enough\n",
              "47666    insufficient\n",
              "2538         seasonal\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHfx9PlyWO9T",
        "colab_type": "code",
        "outputId": "eac03c12-ddba-4c8b-a188-e05965a11b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Get the permutation importance\n",
        "# Notice we don't have to rerun the model\n",
        "\n",
        "score_permuted = pipeline.score(X_val_permuted, y_val) #Calc. accuracy on the permuted val dataset\n",
        "\n",
        "print(f'Validation accuracy with {feature}: {score_with}')\n",
        "print(f'Validation accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation importance: {score_with - score_permuted}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy with quantity: 0.8135521885521886\n",
            "Validation accuracy with quantity permuted: 0.7118686868686869\n",
            "Permutation importance: 0.10168350168350171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDvsGqGXWSQ8",
        "colab_type": "code",
        "outputId": "bac0ef64-369a-43f0-b673-8c7817a22eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# RERUN for a different feature\n",
        "\n",
        "feature = 'gps_height'\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])\n",
        "\n",
        "score_permuted = pipeline.score(X_val_permuted, y_val) #Calc. accuracy on the permuted val dataset\n",
        "\n",
        "print(f'Validation accuracy with {feature}: {score_with}')\n",
        "print(f'Validation accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation importance: {score_with - score_permuted}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation accuracy with gps_height: 0.8135521885521886\n",
            "Validation accuracy with gps_height permuted: 0.8103535353535354\n",
            "Permutation importance: 0.0031986531986532007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LYk19SNYii7"
      },
      "source": [
        "### With eli5 library\n",
        "\n",
        "For more documentation on using this library, see:\n",
        "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
        "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
        "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "eli5 doesn't work with pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpSemTkFFP8i",
        "outputId": "7560da85-8367-4f3f-d3fa-a0611d7bc6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Ignore warnings\n",
        "\n",
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.fit_transform(X_val) \n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q07yW9k-Yii8"
      },
      "source": [
        "### We can use importances for feature selection\n",
        "\n",
        "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZrPFyEMYii9",
        "outputId": "5777e27a-dd59-4b78-a653-d63b7331f90d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "#1. Calculate permutation importances\n",
        "permuter = PermutationImportance(\n",
        "    model, \n",
        "    scoring='accuracy',\n",
        "    n_iter=5,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PermutationImportance(cv='prefit',\n",
              "                      estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                       ccp_alpha=0.0,\n",
              "                                                       class_weight=None,\n",
              "                                                       criterion='gini',\n",
              "                                                       max_depth=None,\n",
              "                                                       max_features='auto',\n",
              "                                                       max_leaf_nodes=None,\n",
              "                                                       max_samples=None,\n",
              "                                                       min_impurity_decrease=0.0,\n",
              "                                                       min_impurity_split=None,\n",
              "                                                       min_samples_leaf=1,\n",
              "                                                       min_samples_split=2,\n",
              "                                                       min_weight_fraction_leaf=0.0,\n",
              "                                                       n_estimators=100,\n",
              "                                                       n_jobs=-1,\n",
              "                                                       oob_score=False,\n",
              "                                                       random_state=42,\n",
              "                                                       verbose=0,\n",
              "                                                       warm_start=False),\n",
              "                      n_iter=5, random_state=42, refit=True,\n",
              "                      scoring='accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvencuAhciRv",
        "colab_type": "code",
        "outputId": "b5463b3f-5896-4da0-8d80-6c4491e70a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "feature_names = X_val.columns.tolist()\n",
        "pd.Series(permuter.feature_importances_, feature_names).sort_values(ascending=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "quantity                     0.101717\n",
              "amount_tsh                   0.010926\n",
              "extraction_type_class        0.010488\n",
              "waterpoint_type              0.010337\n",
              "longitude                    0.008855\n",
              "waterpoint_type_group        0.006936\n",
              "latitude                     0.006481\n",
              "population                   0.006397\n",
              "subvillage                   0.003535\n",
              "years                        0.002963\n",
              "payment                      0.002862\n",
              "public_meeting               0.002795\n",
              "construction_year            0.002694\n",
              "district_code                0.002492\n",
              "gps_height                   0.002088\n",
              "source                       0.001650\n",
              "day_recorded                 0.001650\n",
              "extraction_type_group        0.001616\n",
              "funder                       0.001599\n",
              "wpt_name                     0.001263\n",
              "region                       0.001145\n",
              "scheme_name                  0.001094\n",
              "permit                       0.001027\n",
              "lga                          0.000943\n",
              "month_recorded               0.000909\n",
              "scheme_management            0.000892\n",
              "region_code                  0.000842\n",
              "longitude_MISSING            0.000724\n",
              "management                   0.000657\n",
              "ward                         0.000522\n",
              "water_quality                0.000488\n",
              "extraction_type              0.000488\n",
              "year_recorded                0.000404\n",
              "num_private                  0.000337\n",
              "gps_height_MISSING           0.000320\n",
              "installer                    0.000236\n",
              "years_MISSING                0.000185\n",
              "source_class                 0.000168\n",
              "construction_year_MISSING    0.000135\n",
              "latitude_MISSING             0.000135\n",
              "population_MISSING           0.000135\n",
              "source_type                  0.000101\n",
              "management_group            -0.000236\n",
              "quality_group               -0.000539\n",
              "basin                       -0.001313\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01TV2hTadMRG",
        "colab_type": "code",
        "outputId": "922d0c2d-ffe9-4f10-cd34-4ec80b77f172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "# 2. Display permutation importances (the nice way)\n",
        "eli5.show_weights(\n",
        "    permuter,\n",
        "    top=None, #Shows all features\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1017\n",
              "                \n",
              "                    &plusmn; 0.0027\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0109\n",
              "                \n",
              "                    &plusmn; 0.0025\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.92%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0105\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0103\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0089\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.95%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0069\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.09%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0065\n",
              "                \n",
              "                    &plusmn; 0.0022\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.12%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0064\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.10%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0035\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0026\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0029\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.38%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.43%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0027\n",
              "                \n",
              "                    &plusmn; 0.0029\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.51%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0025\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.68%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0021\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.90%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.91%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.07%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0013\n",
              "                \n",
              "                    &plusmn; 0.0015\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.14%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.16%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.20%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0010\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.26%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0021\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0017\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.30%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.50%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.52%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.52%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.58%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.65%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.71%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0020\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.76%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0002\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0002\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.84%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.71%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.49%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0005\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.05%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0013\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNN7F_1rd3p1",
        "colab_type": "code",
        "outputId": "41a39f79-46ea-4573-b2d6-88f412e4336b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Shape before removing features: ', X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before removing features:  (47520, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zngcl9fJeA2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minimum_importance = 0 \n",
        "\n",
        "mask = permuter.feature_importances_ > minimum_importance\n",
        "features = X_train.columns[mask] # Subsetting with just the important features\n",
        "X_train = X_train[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ubsu_I3efK_",
        "colab_type": "code",
        "outputId": "5e342813-b9f6-4302-c4ae-1d5ec53fe2e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_val = X_val[features]\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy: {score_with}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.812037037037037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fl67bCR7WY6j"
      },
      "source": [
        "# Use xgboost for gradient boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9aZXNBlKDbu",
        "colab_type": "text"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX8D3N1dKDbv",
        "colab_type": "text"
      },
      "source": [
        "In the Random Forest lesson, you learned this advice:\n",
        "\n",
        "#### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
        "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
        "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
        "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
        "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
        "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVk0zIMyKDbw",
        "colab_type": "text"
      },
      "source": [
        "Like Random Forest, Gradient Boosting uses ensembles of trees. But the details of the ensembling technique are different:\n",
        "\n",
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "Here's an excerpt from [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        ">\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        ">\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        ">\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
        ">\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown.\n",
        "\n",
        "This high-level overview is all you need to know for now. If you want to go deeper, we recommend you watch the StatQuest videos on gradient boosting!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ4n-VcAKDby",
        "colab_type": "text"
      },
      "source": [
        "Let's write some code. We have lots of options for which libraries to use:\n",
        "\n",
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXBbvk8BKDbz",
        "colab_type": "text"
      },
      "source": [
        "In this lesson, you'll use a new library, xgboost — But it has an API that's almost the same as scikit-learn, so it won't be a hard adjustment!\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wsnJRKjfWYph",
        "outputId": "e8faeb39-0efb-4316-b4be-e3526e115c88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(),\n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'installer', 'wpt_name',\n",
              "                                      'subvillage', 'region', 'lga', 'ward',\n",
              "                                      'public_meeting', 'scheme_management',\n",
              "                                      'scheme_name', 'permit',\n",
              "                                      'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'payment', 'water_quality', 'quantity',\n",
              "                                      'source', 'source_type', 'source_class',\n",
              "                                      'w...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQSBFm3oj3qn",
        "colab_type": "code",
        "outputId": "663023c5-35ac-47f9-f4fe-89dea808cec4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7455387205387205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eCjVSlD_XJr2"
      },
      "source": [
        "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
        "\n",
        "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
        "\n",
        "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
        "\n",
        "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
        "\n",
        "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
        "\n",
        "#### XGBoost parameters\n",
        "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
        "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZNX3IKftXBFS",
        "outputId": "69aa0b33-fd66-405b-eadf-d5acfce9a1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000, # <= [up to] 1000 trees (but depends on early stopping)\n",
        "    max_depth = 7, # Deeper Trees for high cardinality categories\n",
        "    learning_rate = 0.5, \n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "eval_set = [(X_train_encoded, y_train),\n",
        "            (X_val_encoded, y_val)]\n",
        "\n",
        "model.fit(X_train_encoded, y_train,\n",
        "          eval_set=eval_set,\n",
        "          eval_metric='merror',\n",
        "          early_stopping_rounds=50 ) # Stop if the score hasn't imporved in the last 50 rounds)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.25061\tvalidation_1-merror:0.259848\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.235501\tvalidation_1-merror:0.24638\n",
            "[2]\tvalidation_0-merror:0.229756\tvalidation_1-merror:0.242088\n",
            "[3]\tvalidation_0-merror:0.226221\tvalidation_1-merror:0.241414\n",
            "[4]\tvalidation_0-merror:0.219066\tvalidation_1-merror:0.235522\n",
            "[5]\tvalidation_0-merror:0.210795\tvalidation_1-merror:0.228199\n",
            "[6]\tvalidation_0-merror:0.205577\tvalidation_1-merror:0.226263\n",
            "[7]\tvalidation_0-merror:0.200715\tvalidation_1-merror:0.224579\n",
            "[8]\tvalidation_0-merror:0.194087\tvalidation_1-merror:0.221296\n",
            "[9]\tvalidation_0-merror:0.191709\tvalidation_1-merror:0.219865\n",
            "[10]\tvalidation_0-merror:0.187879\tvalidation_1-merror:0.218182\n",
            "[11]\tvalidation_0-merror:0.184217\tvalidation_1-merror:0.218519\n",
            "[12]\tvalidation_0-merror:0.182513\tvalidation_1-merror:0.217508\n",
            "[13]\tvalidation_0-merror:0.180261\tvalidation_1-merror:0.215825\n",
            "[14]\tvalidation_0-merror:0.175505\tvalidation_1-merror:0.213889\n",
            "[15]\tvalidation_0-merror:0.173422\tvalidation_1-merror:0.213721\n",
            "[16]\tvalidation_0-merror:0.171717\tvalidation_1-merror:0.213636\n",
            "[17]\tvalidation_0-merror:0.169066\tvalidation_1-merror:0.213215\n",
            "[18]\tvalidation_0-merror:0.166856\tvalidation_1-merror:0.212963\n",
            "[19]\tvalidation_0-merror:0.162984\tvalidation_1-merror:0.211027\n",
            "[20]\tvalidation_0-merror:0.161195\tvalidation_1-merror:0.210774\n",
            "[21]\tvalidation_0-merror:0.158859\tvalidation_1-merror:0.209428\n",
            "[22]\tvalidation_0-merror:0.157218\tvalidation_1-merror:0.208249\n",
            "[23]\tvalidation_0-merror:0.15484\tvalidation_1-merror:0.207071\n",
            "[24]\tvalidation_0-merror:0.153367\tvalidation_1-merror:0.206818\n",
            "[25]\tvalidation_0-merror:0.152231\tvalidation_1-merror:0.207323\n",
            "[26]\tvalidation_0-merror:0.151515\tvalidation_1-merror:0.206734\n",
            "[27]\tvalidation_0-merror:0.149537\tvalidation_1-merror:0.206397\n",
            "[28]\tvalidation_0-merror:0.148106\tvalidation_1-merror:0.205303\n",
            "[29]\tvalidation_0-merror:0.146465\tvalidation_1-merror:0.205892\n",
            "[30]\tvalidation_0-merror:0.144865\tvalidation_1-merror:0.205724\n",
            "[31]\tvalidation_0-merror:0.143161\tvalidation_1-merror:0.206734\n",
            "[32]\tvalidation_0-merror:0.140699\tvalidation_1-merror:0.206481\n",
            "[33]\tvalidation_0-merror:0.139604\tvalidation_1-merror:0.204966\n",
            "[34]\tvalidation_0-merror:0.137942\tvalidation_1-merror:0.20505\n",
            "[35]\tvalidation_0-merror:0.137037\tvalidation_1-merror:0.204882\n",
            "[36]\tvalidation_0-merror:0.135627\tvalidation_1-merror:0.203956\n",
            "[37]\tvalidation_0-merror:0.13388\tvalidation_1-merror:0.205387\n",
            "[38]\tvalidation_0-merror:0.132281\tvalidation_1-merror:0.204545\n",
            "[39]\tvalidation_0-merror:0.129819\tvalidation_1-merror:0.204125\n",
            "[40]\tvalidation_0-merror:0.128241\tvalidation_1-merror:0.203956\n",
            "[41]\tvalidation_0-merror:0.12721\tvalidation_1-merror:0.203199\n",
            "[42]\tvalidation_0-merror:0.126599\tvalidation_1-merror:0.203114\n",
            "[43]\tvalidation_0-merror:0.125442\tvalidation_1-merror:0.20303\n",
            "[44]\tvalidation_0-merror:0.124074\tvalidation_1-merror:0.202273\n",
            "[45]\tvalidation_0-merror:0.122327\tvalidation_1-merror:0.20202\n",
            "[46]\tvalidation_0-merror:0.121296\tvalidation_1-merror:0.201599\n",
            "[47]\tvalidation_0-merror:0.12077\tvalidation_1-merror:0.202104\n",
            "[48]\tvalidation_0-merror:0.11854\tvalidation_1-merror:0.20202\n",
            "[49]\tvalidation_0-merror:0.117003\tvalidation_1-merror:0.202946\n",
            "[50]\tvalidation_0-merror:0.115088\tvalidation_1-merror:0.203451\n",
            "[51]\tvalidation_0-merror:0.113826\tvalidation_1-merror:0.20362\n",
            "[52]\tvalidation_0-merror:0.112037\tvalidation_1-merror:0.20303\n",
            "[53]\tvalidation_0-merror:0.111216\tvalidation_1-merror:0.203367\n",
            "[54]\tvalidation_0-merror:0.110438\tvalidation_1-merror:0.202609\n",
            "[55]\tvalidation_0-merror:0.109512\tvalidation_1-merror:0.201347\n",
            "[56]\tvalidation_0-merror:0.107828\tvalidation_1-merror:0.200421\n",
            "[57]\tvalidation_0-merror:0.106587\tvalidation_1-merror:0.200421\n",
            "[58]\tvalidation_0-merror:0.105492\tvalidation_1-merror:0.199495\n",
            "[59]\tvalidation_0-merror:0.105029\tvalidation_1-merror:0.19899\n",
            "[60]\tvalidation_0-merror:0.104251\tvalidation_1-merror:0.199158\n",
            "[61]\tvalidation_0-merror:0.10303\tvalidation_1-merror:0.200168\n",
            "[62]\tvalidation_0-merror:0.101284\tvalidation_1-merror:0.200337\n",
            "[63]\tvalidation_0-merror:0.100168\tvalidation_1-merror:0.200337\n",
            "[64]\tvalidation_0-merror:0.098569\tvalidation_1-merror:0.200421\n",
            "[65]\tvalidation_0-merror:0.097938\tvalidation_1-merror:0.200589\n",
            "[66]\tvalidation_0-merror:0.096928\tvalidation_1-merror:0.200505\n",
            "[67]\tvalidation_0-merror:0.096591\tvalidation_1-merror:0.200589\n",
            "[68]\tvalidation_0-merror:0.095328\tvalidation_1-merror:0.200421\n",
            "[69]\tvalidation_0-merror:0.094402\tvalidation_1-merror:0.199663\n",
            "[70]\tvalidation_0-merror:0.092845\tvalidation_1-merror:0.200337\n",
            "[71]\tvalidation_0-merror:0.091835\tvalidation_1-merror:0.199663\n",
            "[72]\tvalidation_0-merror:0.090636\tvalidation_1-merror:0.199074\n",
            "[73]\tvalidation_0-merror:0.08952\tvalidation_1-merror:0.200084\n",
            "[74]\tvalidation_0-merror:0.088321\tvalidation_1-merror:0.200421\n",
            "[75]\tvalidation_0-merror:0.087311\tvalidation_1-merror:0.201599\n",
            "[76]\tvalidation_0-merror:0.086279\tvalidation_1-merror:0.200758\n",
            "[77]\tvalidation_0-merror:0.085417\tvalidation_1-merror:0.20101\n",
            "[78]\tvalidation_0-merror:0.083986\tvalidation_1-merror:0.200673\n",
            "[79]\tvalidation_0-merror:0.083039\tvalidation_1-merror:0.199495\n",
            "[80]\tvalidation_0-merror:0.082197\tvalidation_1-merror:0.199327\n",
            "[81]\tvalidation_0-merror:0.081545\tvalidation_1-merror:0.199747\n",
            "[82]\tvalidation_0-merror:0.080661\tvalidation_1-merror:0.200758\n",
            "[83]\tvalidation_0-merror:0.080177\tvalidation_1-merror:0.200084\n",
            "[84]\tvalidation_0-merror:0.078956\tvalidation_1-merror:0.199916\n",
            "[85]\tvalidation_0-merror:0.078072\tvalidation_1-merror:0.198906\n",
            "[86]\tvalidation_0-merror:0.077189\tvalidation_1-merror:0.199411\n",
            "[87]\tvalidation_0-merror:0.076242\tvalidation_1-merror:0.199158\n",
            "[88]\tvalidation_0-merror:0.075379\tvalidation_1-merror:0.198148\n",
            "[89]\tvalidation_0-merror:0.074579\tvalidation_1-merror:0.198232\n",
            "[90]\tvalidation_0-merror:0.073295\tvalidation_1-merror:0.198316\n",
            "[91]\tvalidation_0-merror:0.072601\tvalidation_1-merror:0.197475\n",
            "[92]\tvalidation_0-merror:0.070981\tvalidation_1-merror:0.198485\n",
            "[93]\tvalidation_0-merror:0.070034\tvalidation_1-merror:0.198822\n",
            "[94]\tvalidation_0-merror:0.068687\tvalidation_1-merror:0.198316\n",
            "[95]\tvalidation_0-merror:0.068413\tvalidation_1-merror:0.19798\n",
            "[96]\tvalidation_0-merror:0.067845\tvalidation_1-merror:0.198316\n",
            "[97]\tvalidation_0-merror:0.067109\tvalidation_1-merror:0.197559\n",
            "[98]\tvalidation_0-merror:0.066793\tvalidation_1-merror:0.19798\n",
            "[99]\tvalidation_0-merror:0.066435\tvalidation_1-merror:0.197306\n",
            "[100]\tvalidation_0-merror:0.066204\tvalidation_1-merror:0.197559\n",
            "[101]\tvalidation_0-merror:0.065972\tvalidation_1-merror:0.19798\n",
            "[102]\tvalidation_0-merror:0.065488\tvalidation_1-merror:0.197643\n",
            "[103]\tvalidation_0-merror:0.064731\tvalidation_1-merror:0.197475\n",
            "[104]\tvalidation_0-merror:0.064205\tvalidation_1-merror:0.198653\n",
            "[105]\tvalidation_0-merror:0.063152\tvalidation_1-merror:0.199158\n",
            "[106]\tvalidation_0-merror:0.062269\tvalidation_1-merror:0.198906\n",
            "[107]\tvalidation_0-merror:0.062079\tvalidation_1-merror:0.199074\n",
            "[108]\tvalidation_0-merror:0.061322\tvalidation_1-merror:0.199242\n",
            "[109]\tvalidation_0-merror:0.060227\tvalidation_1-merror:0.199242\n",
            "[110]\tvalidation_0-merror:0.059449\tvalidation_1-merror:0.199832\n",
            "[111]\tvalidation_0-merror:0.058754\tvalidation_1-merror:0.199495\n",
            "[112]\tvalidation_0-merror:0.057976\tvalidation_1-merror:0.199411\n",
            "[113]\tvalidation_0-merror:0.057113\tvalidation_1-merror:0.199579\n",
            "[114]\tvalidation_0-merror:0.056229\tvalidation_1-merror:0.200168\n",
            "[115]\tvalidation_0-merror:0.055724\tvalidation_1-merror:0.2\n",
            "[116]\tvalidation_0-merror:0.054987\tvalidation_1-merror:0.199832\n",
            "[117]\tvalidation_0-merror:0.054461\tvalidation_1-merror:0.199747\n",
            "[118]\tvalidation_0-merror:0.053914\tvalidation_1-merror:0.199579\n",
            "[119]\tvalidation_0-merror:0.053283\tvalidation_1-merror:0.200084\n",
            "[120]\tvalidation_0-merror:0.052231\tvalidation_1-merror:0.199495\n",
            "[121]\tvalidation_0-merror:0.05141\tvalidation_1-merror:0.199579\n",
            "[122]\tvalidation_0-merror:0.050652\tvalidation_1-merror:0.199158\n",
            "[123]\tvalidation_0-merror:0.049937\tvalidation_1-merror:0.199579\n",
            "[124]\tvalidation_0-merror:0.049474\tvalidation_1-merror:0.200168\n",
            "[125]\tvalidation_0-merror:0.0492\tvalidation_1-merror:0.199916\n",
            "[126]\tvalidation_0-merror:0.048716\tvalidation_1-merror:0.199916\n",
            "[127]\tvalidation_0-merror:0.048253\tvalidation_1-merror:0.200084\n",
            "[128]\tvalidation_0-merror:0.047811\tvalidation_1-merror:0.199579\n",
            "[129]\tvalidation_0-merror:0.047412\tvalidation_1-merror:0.200337\n",
            "[130]\tvalidation_0-merror:0.047075\tvalidation_1-merror:0.200084\n",
            "[131]\tvalidation_0-merror:0.046338\tvalidation_1-merror:0.199832\n",
            "[132]\tvalidation_0-merror:0.045686\tvalidation_1-merror:0.200084\n",
            "[133]\tvalidation_0-merror:0.045139\tvalidation_1-merror:0.199663\n",
            "[134]\tvalidation_0-merror:0.044739\tvalidation_1-merror:0.2\n",
            "[135]\tvalidation_0-merror:0.044108\tvalidation_1-merror:0.199747\n",
            "[136]\tvalidation_0-merror:0.043582\tvalidation_1-merror:0.199916\n",
            "[137]\tvalidation_0-merror:0.042908\tvalidation_1-merror:0.200337\n",
            "[138]\tvalidation_0-merror:0.042698\tvalidation_1-merror:0.199916\n",
            "[139]\tvalidation_0-merror:0.042298\tvalidation_1-merror:0.199747\n",
            "[140]\tvalidation_0-merror:0.041919\tvalidation_1-merror:0.199411\n",
            "[141]\tvalidation_0-merror:0.041204\tvalidation_1-merror:0.199747\n",
            "[142]\tvalidation_0-merror:0.040341\tvalidation_1-merror:0.198906\n",
            "[143]\tvalidation_0-merror:0.040004\tvalidation_1-merror:0.199074\n",
            "[144]\tvalidation_0-merror:0.038973\tvalidation_1-merror:0.198569\n",
            "[145]\tvalidation_0-merror:0.038657\tvalidation_1-merror:0.198653\n",
            "[146]\tvalidation_0-merror:0.038594\tvalidation_1-merror:0.198401\n",
            "[147]\tvalidation_0-merror:0.037984\tvalidation_1-merror:0.198401\n",
            "[148]\tvalidation_0-merror:0.0375\tvalidation_1-merror:0.198316\n",
            "[149]\tvalidation_0-merror:0.037079\tvalidation_1-merror:0.198822\n",
            "Stopping. Best iteration:\n",
            "[99]\tvalidation_0-merror:0.066435\tvalidation_1-merror:0.197306\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.5, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jgbBcytmvkV",
        "colab_type": "code",
        "outputId": "5b44722e-8b89-4c32-94b3-3e12181d0107",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label=\"Train\")\n",
        "plt.plot(epoch, val_error, label=\"Validation\")\n",
        "plt.ylabel('Classification Error')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "plt.ylim((0.18, 0.22)) #Turn this on and off to see the full plt \n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAELCAYAAADOeWEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoHLZbaRmvXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZF7-ml6BhRRf"
      },
      "source": [
        "### Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_BDMY4yKDb7",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint. Complete these tasks for your project, and document your work.\n",
        "\n",
        "- Continue to clean and explore your data. Make exploratory visualizations.\n",
        "- Fit a model. Does it beat your baseline?\n",
        "- Try xgboost.\n",
        "- Get your model's permutation importances.\n",
        "\n",
        "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
        "\n",
        "But, if you aren't ready to try xgboost and permutation importances with your dataset today, you can practice with another dataset instead. You may choose any dataset you've worked with previously."
      ]
    }
  ]
}